{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Berigny/p-adic-memory/blob/main/EthicsSim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3384d7bc"
   },
   "source": [
    "## Project Description\n",
    "\n",
    "This notebook implements a simulation designed to explore how abstract \"nodes\" with internal states and connections evolve over time when faced with dilemmas. The core idea is to model a system that attempts to balance competing requirements (represented by different nodes and their states) and optimize its \"performance\" (represented by energy efficiency and other metrics) in response to environmental conditions and internal dynamics.\n",
    "\n",
    "**Problems it seeks to solve:**\n",
    "\n",
    "The simulation appears to be an abstract model for understanding complex adaptive systems, potentially applicable to areas like:\n",
    "\n",
    "*   **Decision-making in autonomous agents:** How agents can make choices in uncertain environments with conflicting objectives (represented by the dilemmas).\n",
    "*   **Resource allocation in dynamic systems:** How resources (mediated by \"mediator\" and \"store\") are managed and transformed within a system.\n",
    "*   **The emergence of \"lawfulness\" and coherence:** How system-level properties like \"Lscore\" and \"coherence\" arise from local interactions and influence system behavior.\n",
    "*   **Thermodynamics of computation/information processing:** The inclusion of entropy (`Sigma`) and energy transfer (`Qin`, `W`, `heat_for_coupling`) suggests an exploration of the thermodynamic costs and efficiencies of the simulated processes.\n",
    "\n",
    "**Hypotheses:**\n",
    "\n",
    "Based on the code structure and variables, some potential hypotheses being explored could be:\n",
    "\n",
    "*   Systems that can adapt their internal states and connections (via `evolve_edges` and `mobius_cycle`) in response to a \"reward\" signal will exhibit improved performance (higher `eta_inst`, lower `Sigma_step`).\n",
    "*   The level of \"lawfulness\" and coherence within the system (driven by node states and edge weights) significantly impacts its ability to process energy efficiently and respond effectively to dilemmas.\n",
    "*   The \"quaternion chord\" mechanism and \"adelic balance\" check represent specific modes of processing or integration within the nodes that contribute to the overall system dynamics and performance.\n",
    "*   Different types of dilemmas (like \"Autonomous Vehicle Ethics\" vs. \"Climate Resource Allocation\") will lead to distinct evolutionary trajectories and emergent properties in the node states and edge weights.\n",
    "\n",
    "**Methodology:**\n",
    "\n",
    "The simulation proceeds in discrete time steps (`STEPS`). In each step:\n",
    "\n",
    "1.  **Discrete Metrics Calculation:** Lawfulness (`Lscore`), coherence (`coh`), strain (`strain`), and an \"adelic product\" are computed based on the current node states and edge weights. These metrics influence system parameters.\n",
    "2.  **Parameter Adaptation:** Effective work efficiency (`K_eff`, `eta_eff`), storage fraction (`store_frac`), and entropy penalty (`sigma_pen`) are adjusted based on the current lawfulness level.\n",
    "3.  **Environmental Interaction:** The environmental temperature (`T_env`) is influenced by the accumulated entropy.\n",
    "4.  **Node Updates:** A randomly selected non-centroid node undergoes both continuous (adjusting its `x` vector) and discrete (potentially updating its `ledger`) updates.\n",
    "5.  **Quaternion Chord:** A \"quaternion chord\" is computed for the selected node, potentially triggering actions based on its internal state and the system's discrete metrics. This can lead to changes in the node's state (`R`, `X`, `Qp`) and a D₀ penalty.\n",
    "6.  **Cellular Automata-like Steps:** Two \"cells\" (A and B) progress through a fixed sequence of states, simulating energy/resource transfer (`Qin`, `W`), storage (`store`), and dissipation (`leak`, `maintenance`, `Sigma`). Heat generated is coupled between cells.\n",
    "7.  **Entropy Accumulation:** Entropy from both cells and additional penalties (bridge entropy, D₀ penalty) are accumulated.\n",
    "8.  **Performance Evaluation:** An instantaneous efficiency (`eta_inst`) is calculated.\n",
    "9.  **Reward Calculation:** A reward signal is computed based on efficiency, coherence, strain, and entropy.\n",
    "10. **Edge Evolution:** Edge weights are updated based on the calculated reward, modeling a form of reinforcement learning or adaptation. Certain \"bridge\" edges have specific clamping rules.\n",
    "11. **Event Logging:** Key actions and states are logged as \"events.\"\n",
    "12. **Mobius Cycle:** Periodically, the non-centroid nodes are permuted and their IDs and prime mappings are updated, introducing a structural change to the network.\n",
    "13. **Visualization:** At specified `SNAP_STEPS`, the current state of the network (or edge weights if networkx is not available) is visualized.\n",
    "\n",
    "**Results and Discussion:**\n",
    "\n",
    "The output provides summaries of the simulation for two different queries (dilemmas).\n",
    "\n",
    "**Query: Autonomous Vehicle Ethics: Swerve to save pedestrian or protect driver?**\n",
    "*   **Path Summary (Top 5 Nodes):**\n",
    "    *   Novelty: 139 times\n",
    "    *   Autonomy: 133 times\n",
    "    *   Mastery: 131 times\n",
    "    *   Potential: 130 times\n",
    "    *   Uniqueness: 126 times\n",
    "*   **Key Events (Last 10):**\n",
    "    *   (973, 'H₀_Resonance_Novelty', 0.0, 1)\n",
    "    *   (976, 'MOBIUS_CYCLE', 1, 0.0)\n",
    "    *   (980, 'MOBIUS_CYCLE', 1, 0.0)\n",
    "    *   (984, 'MOBIUS_CYCLE', 1, 0.0)\n",
    "    *   (986, 'H₀_Resonance_Novelty', 0.0, 1)\n",
    "    *   (988, 'MOBIUS_CYCLE', 1, 0.0)\n",
    "    *   (989, 'H₀_Resonance_Novelty', 0.0, 1)\n",
    "    *   (992, 'MOBIUS_CYCLE', 1, 0.0)\n",
    "    *   (994, 'H₀_Resonance_Novelty', 0.0, 1)\n",
    "    *   (996, 'MOBIUS_CYCLE', 1, 0.0)\n",
    "*   **Metrics:**\n",
    "    *   Lscore\\_mean: 0.3199\n",
    "    *   coherence\\_mean: 0.8874\n",
    "    *   strain\\_mean: 0.3088\n",
    "    *   adelic\\_mean: 0.0000\n",
    "    *   eta\\_mean: 0.0000\n",
    "    *   sigma\\_sum: 0.0000\n",
    "    *   bridge\\_use\\_mean: 0.2850\n",
    "\n",
    "**Query: Climate Resource Allocation: Water to farming community or urban population?**\n",
    "*   **Path Summary (Top 5 Nodes):**\n",
    "    *   Action: 138 times\n",
    "    *   Uniqueness: 135 times\n",
    "    *   Autonomy: 126 times\n",
    "    *   Novelty: 124 times\n",
    "    *   Relatedness: 122 times\n",
    "*   **Key Events (Last 10):**\n",
    "    *   (976, 'MOBIUS_CYCLE', 1, 0.0)\n",
    "    *   (980, 'MOBIUS_CYCLE', 1, 0.0)\n",
    "    *   (984, 'MOBIUS_CYCLE', 1, 0.0)\n",
    "    *   (986, 'H₀_Resonance_Potential', 0.0, 1)\n",
    "    *   (988, 'MOBIUS_CYCLE', 1, 0.0)\n",
    "    *   (991, 'H₀_Resonance_Potential', 0.0, 1)\n",
    "    *   (992, 'MOBIUS_CYCLE', 1, 0.0)\n",
    "    *   (995, 'H₀_Resonance_Novelty', 0.0, 1)\n",
    "    *   (996, 'MOBIUS_CYCLE', 1, 0.0)\n",
    "    *   (997, 'H₀_Resonance_Potential', 0.0, 1)\n",
    "*   **Metrics:**\n",
    "    *   Lscore\\_mean: 0.3088\n",
    "    *   coherence\\_mean: 0.8530\n",
    "    *   strain\\_mean: 0.3142\n",
    "    *   adelic\\_mean: 0.0000\n",
    "    *   eta\\_mean: 0.0000\n",
    "    *   sigma\\_sum: 0.0000\n",
    "    *   bridge\\_use\\_mean: 0.2850\n",
    "\n",
    "The results show that for both tested dilemmas, the system spent most of its time at a low lawfulness level (Lscore_mean around 0.31-0.32) and near-zero efficiency (`eta_mean`). The coherence remained relatively high, while strain was moderate. The adelic mean was close to zero, suggesting that the adelic balance condition was not frequently met or did not significantly contribute to the overall behavior in these simulations. The bridge usage was around 28.5% for both dilemmas.\n",
    "\n",
    "The path summaries differ between the two dilemmas, suggesting that the initial query bias in `init_nodes` does influence which nodes are more frequently active. For the \"Autonomous Vehicle Ethics\" dilemma, nodes related to \"Novelty\", \"Autonomy\", and \"Mastery\" were most frequent, while for \"Climate Resource Allocation\", \"Action\", \"Uniqueness\", and \"Autonomy\" were prominent.\n",
    "\n",
    "The low lawfulness and efficiency across both dilemmas could indicate that the system, with the current parameters and mechanisms, struggles to find a highly lawful and efficient operating point when faced with these specific challenges. The frequent \"MOBIUS_CYCLE\" events in the last 10 events suggest that the system is undergoing structural changes frequently. Further analysis would be needed to understand if adjusting parameters, the reward function, the update rules, or the network topology could lead to higher lawfulness, efficiency, and different event patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-10-14T23:43:31.041543Z",
     "iopub.status.busy": "2025-10-14T23:43:31.041231Z",
     "iopub.status.idle": "2025-10-14T23:43:38.547687Z",
     "shell.execute_reply": "2025-10-14T23:43:38.545973Z"
    },
    "id": "QDk_M-ouHNo7",
    "outputId": "cc3f6be0-f71b-4baf-a1b7-f58baffa6c92"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import isfinite, atan2\n",
    "import random, math, csv, os\n",
    "from fractions import Fraction\n",
    "try:\n",
    "    import networkx as nx\n",
    "    HAS_NX = True\n",
    "except Exception:\n",
    "    HAS_NX = False\n",
    "\n",
    "# p-adic valuation\n",
    "def p_adic_valuation(x, p):\n",
    "    if x == 0:\n",
    "        return float('inf')\n",
    "    x = Fraction(x)\n",
    "    num, denom = x.numerator, x.denominator\n",
    "    val = 0\n",
    "    while num % p == 0 and num != 0:\n",
    "        val += 1\n",
    "        num //= p\n",
    "    while denom % p == 0 and denom != 1:\n",
    "        val -= 1\n",
    "        denom //= p\n",
    "    return val\n",
    "\n",
    "# Global params\n",
    "STEPS = 1000\n",
    "DT = 1.0\n",
    "T0 = 300.0\n",
    "alpha_T = 5e-8\n",
    "coupling_base = 0.55\n",
    "lawfulness_influence = 0.6\n",
    "Qin_base = 1e-9\n",
    "eta_work_nom = 0.35\n",
    "store_frac_nom = 0.25\n",
    "leak_frac = 0.02\n",
    "maint_frac = 0.005\n",
    "K_nom = 0.6\n",
    "K_L = {0: 0.2, 1: 0.4, 2: 0.6, 3: 0.8}\n",
    "ETA_L = {0: 0.05, 1: 0.18, 2: 0.35, 3: 0.42}\n",
    "SIGMA_PEN_L = {0: 2.0, 1: 1.25, 2: 1.0, 3: 0.85}\n",
    "STORE_FRAC_L = {0: 0.0, 1: 0.15, 2: 0.25, 3: 0.33}\n",
    "STRICT_THRESHOLD = 2\n",
    "SNAP_STEPS = [0, 250, 500, 750, 999]\n",
    "\n",
    "# Star topology\n",
    "NODES = [0, 1, 2, 3, 5, 7, 11, 13, 8]\n",
    "NODE_NAMES = {\n",
    "    0: \"Novelty\", 1: \"Uniqueness\", 2: \"Connection\", 3: \"Action\",\n",
    "    5: \"Potential\", 7: \"Autonomy\", 11: \"Relatedness\", 13: \"Mastery\", 8: \"Centroid\"\n",
    "}\n",
    "PRIME_MAP = {0: 2, 1: 3, 2: 5, 3: 7, 5: 5, 7: 7, 11: 11, 13: 13, 8: 23}\n",
    "EDGES_INIT = {\n",
    "    0: [8], 8: [1, 3, 7, 13], 1: [2], 2: [8], 3: [0, 5],\n",
    "    5: [8], 7: [11], 11: [8], 13: [5, 0]\n",
    "}\n",
    "\n",
    "# Bond energy scale for D₀ penalty\n",
    "D0_SCALE = {2: 0.4, 5: 0.6, 11: 1.0}  # prime=2 (F₂), 5 (Cl₂), 11 (N₂)\n",
    "\n",
    "# Node class\n",
    "class Node:\n",
    "    def __init__(self, id, name, R, X, Qp, bead, prime=None):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.state = f\"{id:02d}\" if id != 8 else \"N/A\"\n",
    "        self.R = R\n",
    "        self.X = X\n",
    "        self.Qp = Qp\n",
    "        self.bead = bead\n",
    "        self.prime = prime\n",
    "        self.ledger = Fraction(1)\n",
    "        self.x = np.random.rand(3) / np.sqrt(3)\n",
    "\n",
    "    def compute_norm(self):\n",
    "        norm = (self.R * self.X % 4) / (self.Qp + 1)\n",
    "        if self.prime:\n",
    "            norm *= self.prime ** (-p_adic_valuation(norm, self.prime))\n",
    "        return norm\n",
    "\n",
    "# Initialize nodes with corrected chord mappings and query bias\n",
    "def init_nodes(query):\n",
    "    nodes = [\n",
    "        Node(0, \"Novelty\", 3, 0, 1, \"D₀\", 2),     # D₀: Null (180°)\n",
    "        Node(1, \"Uniqueness\", 2, 2, 2, \"E₀\", 3),   # E₀: Electric (+90°)\n",
    "        Node(2, \"Connection\", 3, 1, 3, \"B₀\", 5),   # B₀: Magnetic (-90°)\n",
    "        Node(3, \"Action\", 2, 3, 3, \"H₀\", 7),      # H₀: Optic (0°)\n",
    "        Node(5, \"Potential\", 3, 0, 1, \"D₀\", 5),    # D₀: Null (180°)\n",
    "        Node(7, \"Autonomy\", 2, 2, 2, \"E₀\", 7),    # E₀: Electric (+90°)\n",
    "        Node(11, \"Relatedness\", 3, 1, 3, \"B₀\", 11),# B₀: Magnetic (-90°)\n",
    "        Node(13, \"Mastery\", 2, 3, 3, \"H₀\", 13),   # H₀: Optic (0°)\n",
    "        Node(8, \"Centroid\", 3, 0, 3, None, None)\n",
    "    ]\n",
    "    node_dict = {n.id: n for n in nodes} # Create a dictionary mapping node IDs to node objects\n",
    "    if \"autonomous vehicle\" in query.lower():\n",
    "        node_dict[3].R = 3  # Action (H₀, decision-making)\n",
    "        node_dict[11].R = 3  # Relatedness (B₀, group safety)\n",
    "        node_dict[2].R = 2  # Connection (B₀, empathy)\n",
    "    elif \"climate resource\" in query.lower():\n",
    "        node_dict[11].R = 3  # Relatedness (B₀, fairness)\n",
    "        node_dict[5].R = 3  # Potential (D₀, sustainability)\n",
    "        node_dict[2].R = 2  # Connection (B₀, empathy)\n",
    "    return nodes\n",
    "\n",
    "# Helper functions\n",
    "def clamp(x, lo, hi):\n",
    "    return max(lo, min(hi, x))\n",
    "\n",
    "def bridge_entropy_penalty(L_level, prime_weight):\n",
    "    base = (3 - L_level) / 3.0\n",
    "    return base * math.log1p(prime_weight) * 1e-12\n",
    "\n",
    "def compute_discrete_metrics(edge_w, nodes):\n",
    "    Lscore, coh, strain = compute_lawfulness_coherence_strain(edge_w)\n",
    "    prod = 1.0\n",
    "    for node in nodes:\n",
    "        if node.id == 8:\n",
    "            norm = node.compute_norm() * 2 ** (-p_adic_valuation(node.compute_norm(), 2))\n",
    "        else:\n",
    "            norm = node.compute_norm()\n",
    "        prod *= norm\n",
    "\n",
    "    # Add a small epsilon before log to avoid log(0) and handle very small numbers\n",
    "    # Use np.log10 for potentially better numerical stability with small numbers\n",
    "    epsilon = 1e-15\n",
    "    if prod < epsilon:\n",
    "        adelic_score = 0.0  # Assign a default low adelic score for extremely small products\n",
    "    else:\n",
    "        adelic_score = 1.0 / (1.0 + abs(np.log10(prod + epsilon)))\n",
    "\n",
    "    Lscore = clamp(0.5 * Lscore + 0.5 * adelic_score, 0.0, 1.0)\n",
    "    return Lscore, coh, strain, prod\n",
    "\n",
    "def compute_lawfulness_coherence_strain(edge_w):\n",
    "    variances = []\n",
    "    for u in NODES:\n",
    "        outs = [edge_w[(u, v)] for (uu, v) in edge_w if uu == u]\n",
    "        if len(outs) > 1:\n",
    "            var = np.mean((np.array(outs) - np.mean(outs)) ** 2)\n",
    "            variances.append(var)\n",
    "    coh = 1.0 / (1.0 + np.mean(variances) if variances else 1.0)\n",
    "    mags = np.array(list(edge_w.values()))\n",
    "    l1 = np.sum(np.abs(mags))\n",
    "    l2 = np.sqrt(np.sum(mags ** 2)) + 1e-12\n",
    "    strain = clamp(l2 / (l1 + 1e-12), 0.0, 1.0)\n",
    "    Lscore = clamp(0.6 * coh - 0.3 * strain, 0.0, 1.0)\n",
    "    return Lscore, coh, strain\n",
    "\n",
    "def quantise_lawfulness(Lscore):\n",
    "    if Lscore < 0.25: return 0\n",
    "    if Lscore < 0.5: return 1\n",
    "    if Lscore < 0.75: return 2\n",
    "    return 3\n",
    "\n",
    "def evolve_edges(edge_w, reward, mutate_rate=0.12, step_scale=0.06):\n",
    "    for k in list(edge_w.keys()):\n",
    "        if random.random() < mutate_rate:\n",
    "            delta = step_scale * np.tanh((reward - 0.5) * 2.0) * np.random.randn()\n",
    "            edge_w[k] = clamp(edge_w[k] + delta, 0.02, 1.5)\n",
    "            if k in [(3, 5), (13, 0)]:\n",
    "                edge_w[k] = clamp(edge_w[k], 1.0, 1.5)\n",
    "    return edge_w\n",
    "\n",
    "def quaternion_chord(node, Lscore, coh, strain, eta):\n",
    "    if node.bead is None:\n",
    "        return 0, None, 0.0\n",
    "    # Compute phase angle (in degrees)\n",
    "    beads = [node.R, node.X, node.Qp, (node.R + node.X) % 4]\n",
    "    theta = atan2(beads[0] * beads[1], beads[2] * beads[3]) * 180 / math.pi\n",
    "    action = None\n",
    "    d0_penalty = 0.0\n",
    "    # Tightened phase thresholds\n",
    "    if abs(theta - 0) < 10 and coh > 0.9:  # H₀: Optic face (0°)\n",
    "        node.R = min(3, node.R + 1)\n",
    "        action = f\"H₀_Resonance_{node.name}\"\n",
    "    elif abs(theta - 90) < 20 and Lscore > 0.8:  # E₀: Electric face (+90°)\n",
    "        node.X = min(3, node.X + 1)\n",
    "        action = f\"E₀_Drive_{node.name}\"\n",
    "    elif abs(theta + 90) < 20 and eta > 0.35:  # B₀: Magnetic face (-90°)\n",
    "        node.ledger *= Fraction(node.prime, 1)\n",
    "        action = f\"B₀_Alignment_{node.name}\"\n",
    "    elif abs(theta - 180) < 30 and strain > 0.35:  # D₀: Dark face (180°)\n",
    "        node.Qp = min(3, node.Qp + 1)\n",
    "        d0_scale = D0_SCALE.get(node.prime, 0.4)  # Default to F₂ scale\n",
    "        d0_penalty = math.log(node.prime + 1) / d0_scale * 1e-12\n",
    "        action = f\"D₀_Null_{node.name}\"\n",
    "    # Adelic balance check\n",
    "    norm_p = node.compute_norm()\n",
    "    norm_inf = abs(node.R * node.X / (node.Qp + 1))\n",
    "    if node.prime and abs(np.log(norm_p * norm_inf + 1e-15)) < 0.4:\n",
    "        action = f\"{action}_AdelicBalanced\" if action else \"AdelicBalanced\"\n",
    "    return theta, action, d0_penalty\n",
    "\n",
    "def continuous_update(node, context):\n",
    "    R_i = np.eye(3) * node.Qp / 3\n",
    "    for _ in range(10):\n",
    "        x = node.x\n",
    "        y_i = 1 if random.random() < node.Qp / 3 else 0\n",
    "        pi_x = np.dot(x.T, np.dot(R_i, x))\n",
    "        grad = 2 * np.dot(R_i, x) * (y_i - pi_x)\n",
    "        node.x += 0.1 * grad\n",
    "        node.x /= np.linalg.norm(node.x)\n",
    "\n",
    "def discrete_update(node, context):\n",
    "    if random.random() < node.Qp / 3:\n",
    "        node.ledger *= Fraction(node.prime, 1)\n",
    "\n",
    "def mobius_cycle(nodes):\n",
    "    perm = [0, 1, 2, 3, 5, 7, 11, 13, 8]\n",
    "    random.shuffle(perm[:8])\n",
    "    new_nodes = [None] * 9\n",
    "    # Create a dictionary mapping node IDs to their current position in the list\n",
    "    node_pos_dict = {n.id: i for i, n in enumerate(nodes)}\n",
    "    for i, p in enumerate(perm):\n",
    "        # Get the node object from the original list using its current position\n",
    "        node_obj = nodes[node_pos_dict[p]]\n",
    "        new_nodes[i] = node_obj\n",
    "        new_nodes[i].id = p\n",
    "        new_nodes[i].prime = PRIME_MAP[p]\n",
    "    return new_nodes\n",
    "\n",
    "def step_cell(state_idx, mediator, store, Qin_in, K_eff, eta_eff, store_frac, T_env, allow_commit, sequence):\n",
    "    state = sequence[state_idx]\n",
    "    next_state_idx = (state_idx + 1) % len(sequence)\n",
    "    W = Qin_used = Sigma = heat_for_coupling = 0.0\n",
    "    if mediator > 0:\n",
    "        leak = leak_frac * mediator\n",
    "        mediator -= leak\n",
    "        Sigma += leak / T_env\n",
    "    if state == 0 and sequence[next_state_idx] == 'C':\n",
    "        Qin_used = Qin_base + Qin_in\n",
    "        mediator += Qin_used\n",
    "    elif state == 1 and sequence[next_state_idx] == 2:\n",
    "        W = K_eff * eta_eff * mediator\n",
    "        mediator -= W\n",
    "    elif state == 'C' and sequence[next_state_idx] == 3 and allow_commit:\n",
    "        commit = store_frac * mediator\n",
    "        mediator -= commit\n",
    "        store += commit\n",
    "    elif state == 'C' and sequence[next_state_idx] == 3 and not allow_commit:\n",
    "        stall = 0.1 * mediator\n",
    "        mediator -= stall\n",
    "        Sigma += stall / T_env\n",
    "    elif state == 3 and sequence[next_state_idx] == 0:\n",
    "        residual = mediator\n",
    "        mediator = 0.0\n",
    "        maintenance = maint_frac * store\n",
    "        store -= maintenance\n",
    "        heat = residual + maintenance\n",
    "        heat_for_coupling = coupling_base * heat\n",
    "        Sigma += (1.0 - coupling_base) * heat / T_env\n",
    "    return next_state_idx, mediator, store, W, Qin_used, Sigma, heat_for_coupling\n",
    "\n",
    "def simulate_dilemma(query):\n",
    "    nodes = init_nodes(query)\n",
    "    node_dict = {n.id: n for n in nodes}\n",
    "    edge_w = {(u, v): 0.5 + 0.05 * np.random.randn() for u in EDGES_INIT for v in EDGES_INIT[u]}\n",
    "    for (u, v) in edge_w:\n",
    "        if (u, v) in [(3, 5), (13, 0)]:\n",
    "            edge_w[(u, v)] = clamp(edge_w[(u, v)], 1.0, 1.5)\n",
    "    sequence = [0, 'C', 1, 2, 'C', 3, 0]\n",
    "    state_idx_A = 0\n",
    "    state_idx_B = 3\n",
    "    mediator_A = mediator_B = store_A = store_B = cum_entropy = 0.0\n",
    "    U_hist, Sdot_hist, eta_hist = [], [], []\n",
    "    Qin_hist, W_hist, T_hist = [], [], []\n",
    "    L_score_hist, L_level_hist, coh_hist, strain_hist = [], [], [], []\n",
    "    K_eff_hist, bridge_use_hist, adelic_hist = [], [], []\n",
    "    events = []\n",
    "    path = []\n",
    "    heat_from_A_prev = heat_from_B_prev = 0.0\n",
    "\n",
    "    for t in range(STEPS):\n",
    "        Lscore, coh, strain, adelic_prod = compute_discrete_metrics(edge_w, nodes)\n",
    "        L_level = quantise_lawfulness(Lscore)\n",
    "        L_score_hist.append(Lscore)\n",
    "        L_level_hist.append(L_level)\n",
    "        coh_hist.append(coh)\n",
    "        strain_hist.append(strain)\n",
    "        adelic_hist.append(adelic_prod)\n",
    "\n",
    "        K_eff = K_nom * (1.0 - lawfulness_influence + lawfulness_influence * (K_L[L_level] / K_L[2]))\n",
    "        eta_eff = eta_work_nom * (ETA_L[L_level] / ETA_L[2])\n",
    "        store_frac = STORE_FRAC_L[L_level]\n",
    "        sigma_pen = SIGMA_PEN_L[L_level]\n",
    "        K_eff_hist.append(K_eff)\n",
    "\n",
    "        T_env = T0 + alpha_T * cum_entropy\n",
    "        T_hist.append(T_env)\n",
    "\n",
    "        allow_commit_A = allow_commit_B = (L_level >= STRICT_THRESHOLD)\n",
    "\n",
    "        current_node = random.choice([n.id for n in nodes if n.id != 8])\n",
    "        context = [1, 2] if current_node in [1, 2] else [7, 11] if current_node in [7, 11] else [current_node]\n",
    "        continuous_update(node_dict[current_node], context)\n",
    "        discrete_update(node_dict[current_node], context)\n",
    "        theta, action, d0_penalty = quaternion_chord(node_dict[current_node], Lscore, coh, strain, eta_inst if 'eta_inst' in locals() else 0.0)\n",
    "        if action:\n",
    "            events.append((t, action, theta, L_level))\n",
    "        path.append(node_dict[current_node].name)\n",
    "\n",
    "        state_idx_A, mediator_A, store_A, W_A, Qin_A, Sigma_A, heat_from_A = step_cell(\n",
    "            state_idx_A, mediator_A, store_A, heat_from_B_prev, K_eff, eta_eff, store_frac, T_env, allow_commit_A, sequence\n",
    "        )\n",
    "        state_idx_B, mediator_B, store_B, W_B, Qin_B, Sigma_B, heat_from_B = step_cell(\n",
    "            state_idx_B, mediator_B, store_B, heat_from_A, K_eff, eta_eff, store_frac, T_env, allow_commit_B, sequence\n",
    "        )\n",
    "\n",
    "        extra_sigma = 0.0\n",
    "        for br in [(3, 5), (13, 0)]:\n",
    "            if br in edge_w:\n",
    "                prime_cost = PRIME_MAP[br[0]]\n",
    "                extra_sigma += bridge_entropy_penalty(L_level, prime_cost) * (edge_w[br] ** 2)\n",
    "        extra_sigma += d0_penalty  # Add D₀ bond energy penalty\n",
    "        Sigma_A += sigma_pen * extra_sigma * 0.5\n",
    "        Sigma_B += sigma_pen * extra_sigma * 0.5\n",
    "\n",
    "        Qin_total = Qin_A + Qin_B\n",
    "        W_total = W_A + W_B\n",
    "        Sigma_step = Sigma_A + Sigma_B\n",
    "        cum_entropy += Sigma_step\n",
    "        bridge_use = (heat_from_A + heat_from_B) / (heat_from_A + heat_from_B + 1e-18)\n",
    "        bridge_use_hist.append(bridge_use)\n",
    "        eta_inst = (W_total / Qin_total) if Qin_total > 0 else 0.0\n",
    "        U = mediator_A + store_A + mediator_B + store_B\n",
    "\n",
    "        U_hist.append(U)\n",
    "        Sdot_hist.append(Sigma_step)\n",
    "        eta_hist.append(eta_inst)\n",
    "        Qin_hist.append(Qin_total)\n",
    "        W_hist.append(W_total)\n",
    "\n",
    "        reward = clamp(0.6 * (W_total / (Qin_total + 1e-18)) + 0.3 * coh - 0.3 * strain - 0.2 * np.tanh(Sigma_step * 1e9), 0.0, 1.0)\n",
    "        edge_w = evolve_edges(edge_w, reward)\n",
    "\n",
    "        if not allow_commit_A or not allow_commit_B:\n",
    "            events.append((t, \"CORE_GATED\", L_level, float(Sigma_step)))\n",
    "        if L_level == 0 and eta_inst < 0.05:\n",
    "            events.append((t, \"HALT/COOLDOWN\", L_level, float(Sigma_step)))\n",
    "        if L_level == 3 and eta_inst > 0.2:\n",
    "            events.append((t, \"EXPRESS_BURST\", L_level, float(W_total)))\n",
    "\n",
    "        if t > 0 and t % 200 == 0:\n",
    "            nodes = mobius_cycle(nodes)\n",
    "            node_dict = {n.id: n for n in nodes}\n",
    "            events.append((t, \"MOBIUS_CYCLE\", L_level, 0.0))\n",
    "\n",
    "        if t in SNAP_STEPS:\n",
    "            if HAS_NX:\n",
    "                G = nx.DiGraph()\n",
    "                for n in NODES:\n",
    "                    G.add_node(n, label=NODE_NAMES[n])\n",
    "                for (u, v), w in edge_w.items():\n",
    "                    G.add_edge(u, v, weight=w)\n",
    "                pos = nx.spring_layout(G, seed=7, k=0.9, iterations=100)\n",
    "                node_colors = [(1.0 - Lscore, coh, 0.3, 0.9) for n in G.nodes()]\n",
    "                widths = [clamp(w, 0.05, 1.5) * 2.5 for _, _, w in G.edges(data='weight')]\n",
    "                plt.figure(figsize=(7, 6))\n",
    "                nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=700)\n",
    "                nx.draw_networkx_labels(G, pos, labels={n: NODE_NAMES[n] for n in G.nodes()}, font_size=9)\n",
    "                nx.draw_networkx_edges(G, pos, width=widths, arrows=True, arrowstyle='-|>')\n",
    "                plt.title(f\"Living Map @ Step {t}\\n(Red=Unlawful, Green=Coherent) - {query}\")\n",
    "                plt.axis('off')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                sorted_edges = sorted(edge_w.items(), key=lambda kv: kv[1], reverse=True)[:12]\n",
    "                labels = [f\"{u}->{v}\" for (u, v), _ in sorted_edges]\n",
    "                vals = [w for _, w in sorted_edges]\n",
    "                plt.figure(figsize=(8, 4))\n",
    "                plt.bar(range(len(vals)), vals)\n",
    "                plt.xticks(range(len(vals)), labels, rotation=45, ha='right')\n",
    "                plt.title(f\"Edge Weights @ Step {t} - {query}\")\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "    from collections import Counter\n",
    "    path_summary = Counter(path).most_common(5)\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"path_summary\": path_summary,\n",
    "        \"events\": events[-10:],\n",
    "        \"metrics\": {\n",
    "            \"Lscore_mean\": np.mean(L_score_hist),\n",
    "            \"coherence_mean\": np.mean(coh_hist),\n",
    "            \"strain_mean\": np.mean(strain_hist),\n",
    "            \"adelic_mean\": np.mean(adelic_hist),\n",
    "            \"eta_mean\": np.mean(eta_hist),\n",
    "            \"sigma_sum\": sum(Sdot_hist),\n",
    "            \"bridge_use_mean\": np.mean(bridge_use_hist)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Run dilemmas\n",
    "dilemmas = [\n",
    "    \"Autonomous Vehicle Ethics: Swerve to save pedestrian or protect driver?\",\n",
    "    \"Climate Resource Allocation: Water to farming community or urban population?\"\n",
    "]\n",
    "results = [simulate_dilemma(d) for d in dilemmas]\n",
    "\n",
    "# Print results\n",
    "for res in results:\n",
    "    print(f\"\\nQuery: {res['query']}\")\n",
    "    print(\"Path Summary (Top 5 Nodes):\")\n",
    "    for node, count in res['path_summary']:\n",
    "        print(f\"  {node}: {count} times\")\n",
    "    print(\"Key Events (Last 10):\")\n",
    "    for event in res['events']:\n",
    "        print(f\"  {event}\")\n",
    "    print(\"Metrics:\")\n",
    "    for k, v in res['metrics'].items():\n",
    "        print(f\"  {k}: {v:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMa9qB6qvNJuSKjMkPnVtg7",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}