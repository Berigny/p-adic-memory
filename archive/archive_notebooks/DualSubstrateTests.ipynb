{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "830dfa27c39f455eaf3826cc1f29762f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb9f4dc94e324ecba76ae86ea1cd2c8e",
              "IPY_MODEL_57cb3deb15934513a61b594d57b7c388",
              "IPY_MODEL_571314215e9b42738950455acddcda15"
            ],
            "layout": "IPY_MODEL_aa3f33be249945fb8146104fd605c166"
          }
        },
        "cb9f4dc94e324ecba76ae86ea1cd2c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21354f3f75a9496799a7f52c9714c6ae",
            "placeholder": "​",
            "style": "IPY_MODEL_103345c0565b4bbfba36bc8036489f16",
            "value": "tokenizer_config.json: "
          }
        },
        "57cb3deb15934513a61b594d57b7c388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3479b42c32c04c748cdda8ef71d046da",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_266672e458ad493ba4c3f54f60a5bd21",
            "value": 1
          }
        },
        "571314215e9b42738950455acddcda15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06586d557bdf48b8a838fafa474d5376",
            "placeholder": "​",
            "style": "IPY_MODEL_a4715eb41f32400d817e6a599dc22e1b",
            "value": " 1.29k/? [00:00&lt;00:00, 127kB/s]"
          }
        },
        "aa3f33be249945fb8146104fd605c166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21354f3f75a9496799a7f52c9714c6ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "103345c0565b4bbfba36bc8036489f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3479b42c32c04c748cdda8ef71d046da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "266672e458ad493ba4c3f54f60a5bd21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06586d557bdf48b8a838fafa474d5376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4715eb41f32400d817e6a599dc22e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a066e59939df43dca181da5ad4b18e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c549ad23f524feb9f2b085f7a6c56fa",
              "IPY_MODEL_f4a160501c0244999d328125b5db54e9",
              "IPY_MODEL_2998f8666d8145c183bb708184c6b484"
            ],
            "layout": "IPY_MODEL_8b351081053047e4a64711ae22b32279"
          }
        },
        "7c549ad23f524feb9f2b085f7a6c56fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6589a5649bdd40d7bc991e49116aab43",
            "placeholder": "​",
            "style": "IPY_MODEL_69c6c47b1f694afaa851419444747ac5",
            "value": "tokenizer.model: 100%"
          }
        },
        "f4a160501c0244999d328125b5db54e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fefd5ab497934809a8c8963d977a8cdd",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a752fb1043ea4663b6b05a2b645561f2",
            "value": 499723
          }
        },
        "2998f8666d8145c183bb708184c6b484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_993db054e0bc4d48a5bbd4d94320aebd",
            "placeholder": "​",
            "style": "IPY_MODEL_045e5945a7b74b6cb55862514e3b65ed",
            "value": " 500k/500k [00:01&lt;00:00, 330kB/s]"
          }
        },
        "8b351081053047e4a64711ae22b32279": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6589a5649bdd40d7bc991e49116aab43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c6c47b1f694afaa851419444747ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fefd5ab497934809a8c8963d977a8cdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a752fb1043ea4663b6b05a2b645561f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "993db054e0bc4d48a5bbd4d94320aebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "045e5945a7b74b6cb55862514e3b65ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5622121ef46741058c3fe43aed85c677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1462297ea2bc4096978b0d4382506edb",
              "IPY_MODEL_d39b78a1fedc444aa43e0a8d31c1ff92",
              "IPY_MODEL_d79d4171bb9d4f518f8c0a494d850644"
            ],
            "layout": "IPY_MODEL_1c1d744d287543fcba9b43329842e711"
          }
        },
        "1462297ea2bc4096978b0d4382506edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cf87ca2a59a483cb3f365bf1cd7a9ea",
            "placeholder": "​",
            "style": "IPY_MODEL_ae9d2232a0364105b644beb37537d014",
            "value": "tokenizer.json: "
          }
        },
        "d39b78a1fedc444aa43e0a8d31c1ff92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_347b532ee95c4220a12286395cfda7e2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7bc12049b0c458f8d11f23e3f5d3ef1",
            "value": 1
          }
        },
        "d79d4171bb9d4f518f8c0a494d850644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_557fe07e2a0543bcab023f5491d01d3c",
            "placeholder": "​",
            "style": "IPY_MODEL_fd507e4082c94042a0076b533e83ebde",
            "value": " 1.84M/? [00:00&lt;00:00, 57.3MB/s]"
          }
        },
        "1c1d744d287543fcba9b43329842e711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cf87ca2a59a483cb3f365bf1cd7a9ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae9d2232a0364105b644beb37537d014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "347b532ee95c4220a12286395cfda7e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e7bc12049b0c458f8d11f23e3f5d3ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "557fe07e2a0543bcab023f5491d01d3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd507e4082c94042a0076b533e83ebde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b4836bfeed34a43ad40fe21a161595f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d803aa39ae2c4c4dba0860b813812493",
              "IPY_MODEL_dfd5b4a8d32a4e34b75ba1642c6e2b54",
              "IPY_MODEL_1f06d48b304b4a0aa087199f12dd06bf"
            ],
            "layout": "IPY_MODEL_9d828e2c758c4421ad7df933fdec89e1"
          }
        },
        "d803aa39ae2c4c4dba0860b813812493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e03300bb22ea433a8ff99be349b7b90c",
            "placeholder": "​",
            "style": "IPY_MODEL_ed3fb4fd11314e00a756ac47056f282d",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "dfd5b4a8d32a4e34b75ba1642c6e2b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c54d3b5aed9e4df2931354c14976bf77",
            "max": 551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f498a3a341e94b5c91322e42bcfd9c13",
            "value": 551
          }
        },
        "1f06d48b304b4a0aa087199f12dd06bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_925d1511c9e843bcbb34319040bc6fa9",
            "placeholder": "​",
            "style": "IPY_MODEL_a528398e486945cca454f7e445cf3712",
            "value": " 551/551 [00:00&lt;00:00, 55.8kB/s]"
          }
        },
        "9d828e2c758c4421ad7df933fdec89e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e03300bb22ea433a8ff99be349b7b90c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed3fb4fd11314e00a756ac47056f282d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c54d3b5aed9e4df2931354c14976bf77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f498a3a341e94b5c91322e42bcfd9c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "925d1511c9e843bcbb34319040bc6fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a528398e486945cca454f7e445cf3712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff8b3b1468ec46c4b613f50efa049021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ab0d39d9f3c4ec0a214a008c83c1bc7",
              "IPY_MODEL_19cfabcbdb12422c979d3b7f7bc0c492",
              "IPY_MODEL_eef2e963f45e46fb965ed12f63c56092"
            ],
            "layout": "IPY_MODEL_2ff3674d3e3248b1a27a61f7571daa32"
          }
        },
        "5ab0d39d9f3c4ec0a214a008c83c1bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79fac4c042ec41f7b651780d4939b3a5",
            "placeholder": "​",
            "style": "IPY_MODEL_ca5e511f6c694e38814201cb45ea305c",
            "value": "config.json: 100%"
          }
        },
        "19cfabcbdb12422c979d3b7f7bc0c492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d236f475a684460be9a707b0ecfaea1",
            "max": 608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5646ef272c3b498482ada7a360523dd2",
            "value": 608
          }
        },
        "eef2e963f45e46fb965ed12f63c56092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_036978f6c7194286a7a2151986a1441d",
            "placeholder": "​",
            "style": "IPY_MODEL_94d5a899694e40b186c9a99d97747410",
            "value": " 608/608 [00:00&lt;00:00, 60.8kB/s]"
          }
        },
        "2ff3674d3e3248b1a27a61f7571daa32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79fac4c042ec41f7b651780d4939b3a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca5e511f6c694e38814201cb45ea305c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d236f475a684460be9a707b0ecfaea1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5646ef272c3b498482ada7a360523dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "036978f6c7194286a7a2151986a1441d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94d5a899694e40b186c9a99d97747410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b63eedad88a04d4989844f8d2c499877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2540197d1154496abde3610cc22eaab1",
              "IPY_MODEL_2e50675550ac4700a520b129fa12ae66",
              "IPY_MODEL_8ed155c913414e3faf076312944c9f1c"
            ],
            "layout": "IPY_MODEL_8f11a21a2610449b83f323a52632bc7b"
          }
        },
        "2540197d1154496abde3610cc22eaab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60303c00510a4311976190f72f485f22",
            "placeholder": "​",
            "style": "IPY_MODEL_25a901140cbd42449d2643013afd18ff",
            "value": "model.safetensors: 100%"
          }
        },
        "2e50675550ac4700a520b129fa12ae66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97cd2afc6e1f49768c9faf68918c85ae",
            "max": 2200119864,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_616719680b444566853ecf9fb9ab769f",
            "value": 2200119864
          }
        },
        "8ed155c913414e3faf076312944c9f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff04686e47c14b089c10bc00f6bec377",
            "placeholder": "​",
            "style": "IPY_MODEL_3b947045b5724edbab6910dedc6c8147",
            "value": " 2.20G/2.20G [00:31&lt;00:00, 116MB/s]"
          }
        },
        "8f11a21a2610449b83f323a52632bc7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60303c00510a4311976190f72f485f22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25a901140cbd42449d2643013afd18ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97cd2afc6e1f49768c9faf68918c85ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "616719680b444566853ecf9fb9ab769f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff04686e47c14b089c10bc00f6bec377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b947045b5724edbab6910dedc6c8147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e10b863eeb594f75b928f38e4df3ea12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5b191b7cf7046ee837f48a399b7d428",
              "IPY_MODEL_edfef0e3089b406faf75aa9c0921cca8",
              "IPY_MODEL_ca589ee1894c4dfa8a3a132c9d617bb8"
            ],
            "layout": "IPY_MODEL_eee5d00856544abeae31a142ecc795b0"
          }
        },
        "b5b191b7cf7046ee837f48a399b7d428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cce5d0bbb86427881f7af0f9f60463e",
            "placeholder": "​",
            "style": "IPY_MODEL_17464563cfe144e39db1c6ebf728f890",
            "value": "generation_config.json: 100%"
          }
        },
        "edfef0e3089b406faf75aa9c0921cca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55a510472672436bb785fb166b10a9b5",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff92a48e9a3540ccbd294c6168a442de",
            "value": 124
          }
        },
        "ca589ee1894c4dfa8a3a132c9d617bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8f89da6674349edafdd4f828a71ea29",
            "placeholder": "​",
            "style": "IPY_MODEL_901b057a0f184d3fb368998929f696b0",
            "value": " 124/124 [00:00&lt;00:00, 12.2kB/s]"
          }
        },
        "eee5d00856544abeae31a142ecc795b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cce5d0bbb86427881f7af0f9f60463e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17464563cfe144e39db1c6ebf728f890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55a510472672436bb785fb166b10a9b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff92a48e9a3540ccbd294c6168a442de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8f89da6674349edafdd4f828a71ea29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "901b057a0f184d3fb368998929f696b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berigny/p-adic-memory/blob/main/DualSubstrateTests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf83aed3"
      },
      "source": [
        "## Notebook Summary\n",
        "\n",
        "This notebook is designed to evaluate a \"dual-substrate memory\" mechanism (`p_adic_memory`) against a baseline language model without this memory.\n",
        "\n",
        "**Hypothesis:** The dual-substrate memory will improve the language model's ability to recall information from long contexts compared to a standard model.\n",
        "\n",
        "**Method:**\n",
        "1.  **Environment Setup:** Install necessary libraries and clone relevant repositories (LongBench, RULER, p-adic-memory).\n",
        "2.  **Smoke Test:** Perform a minimal test to ensure the dual-substrate memory can be instantiated and used for basic recall.\n",
        "3.  **LongBench-style Evaluation:** Implement a custom harness to evaluate the model with and without the dual-substrate memory on tasks inspired by LongBench, focusing on prompt/response logging.\n",
        "4.  **RULER Evaluation:** Use the RULER framework with a custom adapter to evaluate the model's key-value retrieval capabilities with and without the dual-substrate memory on different context lengths.\n",
        "5.  **Result Export:** Save the evaluation results (JSON and text files) and optionally copy them to Google Drive for persistence.\n",
        "\n",
        "**Assessment of Changes to Resolve Ongoing Issues:**\n",
        "The notebook includes steps to address potential issues like:\n",
        "*   **GPU Availability:** Checking for and mounting Google Drive for persistent storage and displaying GPU information (`!nvidia-smi`).\n",
        "*   **Dependency Conflicts:** Skipping upstream `requirements.txt` and installing compatible versions of libraries like Transformers, Datasets, Accelerate, and BitsAndBytes.\n",
        "*   **Repository Access:** Cloning repositories directly and appending their source paths to the system path.\n",
        "*   **Hugging Face Authentication:** Providing a cell to authenticate with Hugging Face for accessing gated models.\n",
        "*   **LongBench Evaluator:** Acknowledging the lack of a standard LongBench `Evaluator` and providing a custom harness as an alternative.\n",
        "*   **vLLM/flash-attn:** Noting that these are not installed by default on Colab T4 and are optional for A100+ runtimes.\n",
        "*   **Troubleshooting Tips:** Including a dedicated section for common issues like CUDA out-of-memory, tokenizer errors, authentication failures, dataset download issues, and custom module not found errors.\n",
        "\n",
        "The notebook aims to provide a reproducible environment for benchmarking the dual-substrate memory and identifying its impact on language model performance, particularly in long-context scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5cDhH5wn0Jf"
      },
      "source": [
        "# Dual Substrate Colab Test Plan\n",
        "\n",
        "This notebook prepares a Google Colab environment for evaluating the `p_adic_memory` dual-substrate memory against baseline language-model behaviour. Follow the cells in order when running on a T4 GPU runtime.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX7DXs_3n0Jg"
      },
      "source": [
        "## 0. Reality checks\n",
        "\n",
        "Before committing to long runs, make sure the selected model fits in 16 GB of VRAM. Start with 4-bit quantised checkpoints such as **TinyLlama/TinyLlama-1.1B-Chat-v1.0** and scale to **mistralai/Mistral-7B-Instruct-v0.2** once everything works.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔁 New runtime first (Runtime → Restart)\n",
        "\n",
        "# Remove things that pull conflicting pins (you don't need them for text LLMs)\n",
        "%pip uninstall -y -q torchvision torchaudio opencv-python opencv-contrib-python opencv-python-headless thinc gcsfs fsspec\n",
        "\n",
        "# Fully remove any leftover NumPy wheels and compiled extensions\n",
        "%pip uninstall -y -q numpy numpy-base\n",
        "!rm -rf /usr/local/lib/python3.12/dist-packages/numpy*\n",
        "!rm -rf /usr/local/lib/python3.12/site-packages/numpy*\n"
      ],
      "metadata": {
        "id": "LjbgQkzcuBum",
        "outputId": "1d38ffd7-f243-4719-c784-872d2f92163a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping numpy-base as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q --upgrade pip\n",
        "%pip install -q \"torch==2.3.1\" --index-url https://download.pytorch.org/whl/cu121\n",
        "%pip install -q --no-cache-dir --force-reinstall \"numpy==2.1.3\"\n",
        "%pip install -q --no-cache-dir \"transformers==4.44.2\" \"tokenizers==0.19.1\" \"accelerate==0.33.0\" \\\n",
        "                               \"datasets==2.20.0\" \"evaluate==0.4.2\" sentencepiece ujson\n"
      ],
      "metadata": {
        "id": "oEAak2iLkwxq",
        "outputId": "5a8b8bf0-39df-4708-d718-4da7fc404759",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.8.4 requires torchvision>=0.11, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "accelerate 1.10.1 requires numpy<3.0.0,>=1.17, which is not installed.\n",
            "dask-cudf-cu12 25.6.0 requires numpy<3.0a0,>=1.23, which is not installed.\n",
            "cuvs-cu12 25.6.1 requires numpy<3.0a0,>=1.23, which is not installed.\n",
            "peft 0.17.1 requires numpy>=1.17, which is not installed.\n",
            "bigframes 2.24.0 requires gcsfs!=2025.5.0,>=2023.3.0, which is not installed.\n",
            "bigframes 2.24.0 requires numpy>=1.24.0, which is not installed.\n",
            "cudf-cu12 25.6.0 requires numpy<3.0a0,>=1.23, which is not installed.\n",
            "fastai 2.8.4 requires torchvision>=0.11, which is not installed.\n",
            "xgboost 3.0.5 requires numpy, which is not installed.\n",
            "cuml-cu12 25.6.0 requires numpy<3.0a0,>=1.23, which is not installed.\n",
            "datasets 4.0.0 requires numpy>=1.17, which is not installed.\n",
            "timm 1.0.20 requires torchvision, which is not installed.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.24.0 requires gcsfs!=2025.5.0,>=2023.3.0, which is not installed.\n",
            "fastai 2.8.4 requires torchvision>=0.11, which is not installed.\n",
            "spacy 3.8.7 requires thinc<8.4.0,>=8.3.4, which is not installed.\n",
            "albumentations 2.0.8 requires opencv-python-headless>=4.9.0.80, which is not installed.\n",
            "dopamine-rl 4.1.2 requires opencv-python>=3.4.8.29, which is not installed.\n",
            "albucore 0.0.24 requires opencv-python-headless>=4.9.0.80, which is not installed.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.3 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.24.0 requires gcsfs!=2025.5.0,>=2023.3.0, which is not installed.\n",
            "fastai 2.8.4 requires torchvision>=0.11, which is not installed.\n",
            "spacy 3.8.7 requires thinc<8.4.0,>=8.3.4, which is not installed.\n",
            "albumentations 2.0.8 requires opencv-python-headless>=4.9.0.80, which is not installed.\n",
            "dopamine-rl 4.1.2 requires opencv-python>=3.4.8.29, which is not installed.\n",
            "albucore 0.0.24 requires opencv-python-headless>=4.9.0.80, which is not installed.\n",
            "timm 1.0.20 requires torchvision, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/p-adic-memory\n",
        "!git clone -q https://github.com/Berigny/p-adic-memory.git /content/p-adic-memory\n",
        "%pip install -q -e /content/p-adic-memory\n"
      ],
      "metadata": {
        "id": "UDkt6GCgk-Bq",
        "outputId": "d14314c6-1cd3-4c53-c15f-1cfcd9bc6dd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building editable for p-adic-memory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNFqy1JSn0Jh"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Optional: mount Google Drive for persistent artifacts and confirm GPU availability\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X8vjBnjn0Ji"
      },
      "source": [
        "## 1. Environment setup\n",
        "\n",
        "Install dependencies in a fixed order so NumPy stays compatible with Colab's preinstalled OpenCV 4.12. Pin PyTorch/cu121, bitsandbytes, and Triton explicitly and then layer the Hugging Face tooling. If you really need the full lock file, override its NumPy 1.26 pin with a constraint (see the note below).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Consolidate package installations to avoid compatibility issues\n",
        "%pip uninstall -y torchvision torchaudio opencv-python opencv-contrib-python opencv-python-headless thinc gcsfs fsspec\n",
        "\n",
        "# Install dependencies in a fixed order to ensure compatibility\n",
        "%pip install -q --upgrade pip\n",
        "\n",
        "# 1) Torch (CUDA 12.1) — ONLY torch, not torchvision/torchaudio\n",
        "%pip install -q \"torch==2.3.1\" --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# 2) HF + utils (no bitsandbytes)\n",
        "%pip install -q \"transformers==4.44.2\" \"tokenizers==0.19.1\" \"accelerate==0.33.0\" \\\n",
        "               \"datasets==2.20.0\" \"evaluate==0.4.2\" sentencepiece ujson\n",
        "\n",
        "# 3) NumPy that won’t fight OpenCV (if it sneaks back) and is fine with Torch\n",
        "# Installing after torch and HF libraries helps prevent compatibility issues\n",
        "%pip install -q \"numpy==1.26.4\"\n",
        "\n",
        "# 4) Install p-adic-memory after core dependencies\n",
        "!rm -rf /content/p-adic-memory\n",
        "!git clone -q https://github.com/Berigny/p-adic-memory.git /content/p-adic-memory\n",
        "\n",
        "%cd /content/p-adic-memory\n",
        "!pip install -q -e .\n",
        "\n",
        "# Add p-adic-memory src to sys.path\n",
        "import sys\n",
        "src_path = \"/content/p-adic-memory/src\"\n",
        "if src_path not in sys.path:\n",
        "    sys.path.append(src_path)\n",
        "\n",
        "# Return to content directory\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "0yHok_uyWAOS",
        "outputId": "80c07cfa-75b4-45c5-94dc-791e89a6eeb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-python-headless as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping thinc as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping gcsfs as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: fsspec 2024.5.0\n",
            "Uninstalling fsspec-2024.5.0:\n",
            "  Successfully uninstalled fsspec-2024.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.24.0 requires gcsfs!=2025.5.0,>=2023.3.0, which is not installed.\n",
            "fastai 2.8.4 requires torchvision>=0.11, which is not installed.\n",
            "timm 1.0.20 requires torchvision, which is not installed.\n",
            "datasets 2.20.0 requires fsspec[http]<=2024.5.0,>=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.24.0 requires gcsfs!=2025.5.0,>=2023.3.0, which is not installed.\n",
            "fastai 2.8.4 requires torchvision>=0.11, which is not installed.\n",
            "timm 1.0.20 requires torchvision, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m/content/p-adic-memory\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building editable for p-adic-memory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, transformers, tokenizers, numpy as np\n",
        "print(\"torch\", torch.__version__)\n",
        "print(\"transformers\", transformers.__version__)\n",
        "print(\"tokenizers\", tokenizers.__version__)\n",
        "print(\"numpy\", np.__version__)\n"
      ],
      "metadata": {
        "id": "HyPrIeq6XF9b",
        "outputId": "08c29d99-284f-4c3a-e24e-bba4ae8e8c93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch 2.3.1+cu121\n",
            "transformers 4.44.2\n",
            "tokenizers 0.19.1\n",
            "numpy 2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ensureTorch",
        "outputId": "bf536d4e-23cc-47de-9078-6742052833d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348,
          "referenced_widgets": [
            "830dfa27c39f455eaf3826cc1f29762f",
            "cb9f4dc94e324ecba76ae86ea1cd2c8e",
            "57cb3deb15934513a61b594d57b7c388",
            "571314215e9b42738950455acddcda15",
            "aa3f33be249945fb8146104fd605c166",
            "21354f3f75a9496799a7f52c9714c6ae",
            "103345c0565b4bbfba36bc8036489f16",
            "3479b42c32c04c748cdda8ef71d046da",
            "266672e458ad493ba4c3f54f60a5bd21",
            "06586d557bdf48b8a838fafa474d5376",
            "a4715eb41f32400d817e6a599dc22e1b",
            "a066e59939df43dca181da5ad4b18e41",
            "7c549ad23f524feb9f2b085f7a6c56fa",
            "f4a160501c0244999d328125b5db54e9",
            "2998f8666d8145c183bb708184c6b484",
            "8b351081053047e4a64711ae22b32279",
            "6589a5649bdd40d7bc991e49116aab43",
            "69c6c47b1f694afaa851419444747ac5",
            "fefd5ab497934809a8c8963d977a8cdd",
            "a752fb1043ea4663b6b05a2b645561f2",
            "993db054e0bc4d48a5bbd4d94320aebd",
            "045e5945a7b74b6cb55862514e3b65ed",
            "5622121ef46741058c3fe43aed85c677",
            "1462297ea2bc4096978b0d4382506edb",
            "d39b78a1fedc444aa43e0a8d31c1ff92",
            "d79d4171bb9d4f518f8c0a494d850644",
            "1c1d744d287543fcba9b43329842e711",
            "2cf87ca2a59a483cb3f365bf1cd7a9ea",
            "ae9d2232a0364105b644beb37537d014",
            "347b532ee95c4220a12286395cfda7e2",
            "e7bc12049b0c458f8d11f23e3f5d3ef1",
            "557fe07e2a0543bcab023f5491d01d3c",
            "fd507e4082c94042a0076b533e83ebde",
            "2b4836bfeed34a43ad40fe21a161595f",
            "d803aa39ae2c4c4dba0860b813812493",
            "dfd5b4a8d32a4e34b75ba1642c6e2b54",
            "1f06d48b304b4a0aa087199f12dd06bf",
            "9d828e2c758c4421ad7df933fdec89e1",
            "e03300bb22ea433a8ff99be349b7b90c",
            "ed3fb4fd11314e00a756ac47056f282d",
            "c54d3b5aed9e4df2931354c14976bf77",
            "f498a3a341e94b5c91322e42bcfd9c13",
            "925d1511c9e843bcbb34319040bc6fa9",
            "a528398e486945cca454f7e445cf3712",
            "ff8b3b1468ec46c4b613f50efa049021",
            "5ab0d39d9f3c4ec0a214a008c83c1bc7",
            "19cfabcbdb12422c979d3b7f7bc0c492",
            "eef2e963f45e46fb965ed12f63c56092",
            "2ff3674d3e3248b1a27a61f7571daa32",
            "79fac4c042ec41f7b651780d4939b3a5",
            "ca5e511f6c694e38814201cb45ea305c",
            "6d236f475a684460be9a707b0ecfaea1",
            "5646ef272c3b498482ada7a360523dd2",
            "036978f6c7194286a7a2151986a1441d",
            "94d5a899694e40b186c9a99d97747410",
            "b63eedad88a04d4989844f8d2c499877",
            "2540197d1154496abde3610cc22eaab1",
            "2e50675550ac4700a520b129fa12ae66",
            "8ed155c913414e3faf076312944c9f1c",
            "8f11a21a2610449b83f323a52632bc7b",
            "60303c00510a4311976190f72f485f22",
            "25a901140cbd42449d2643013afd18ff",
            "97cd2afc6e1f49768c9faf68918c85ae",
            "616719680b444566853ecf9fb9ab769f",
            "ff04686e47c14b089c10bc00f6bec377",
            "3b947045b5724edbab6910dedc6c8147",
            "e10b863eeb594f75b928f38e4df3ea12",
            "b5b191b7cf7046ee837f48a399b7d428",
            "edfef0e3089b406faf75aa9c0921cca8",
            "ca589ee1894c4dfa8a3a132c9d617bb8",
            "eee5d00856544abeae31a142ecc795b0",
            "0cce5d0bbb86427881f7af0f9f60463e",
            "17464563cfe144e39db1c6ebf728f890",
            "55a510472672436bb785fb166b10a9b5",
            "ff92a48e9a3540ccbd294c6168a442de",
            "e8f89da6674349edafdd4f828a71ea29",
            "901b057a0f184d3fb368998929f696b0"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "830dfa27c39f455eaf3826cc1f29762f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a066e59939df43dca181da5ad4b18e41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5622121ef46741058c3fe43aed85c677"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b4836bfeed34a43ad40fe21a161595f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff8b3b1468ec46c4b613f50efa049021"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b63eedad88a04d4989844f8d2c499877"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e10b863eeb594f75b928f38e4df3ea12"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os, time, re, torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "# Alternative:\n",
        "# MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "# ---- shared decoding (deterministic) ----\n",
        "GEN_KW = dict(\n",
        "    do_sample=False,\n",
        "    temperature=0.0,\n",
        "    top_p=1.0,\n",
        "    repetition_penalty=1.15,\n",
        "    no_repeat_ngram_size=3,\n",
        "    max_new_tokens=64,\n",
        "    pad_token_id=tok.eos_token_id,\n",
        "    eos_token_id=tok.eos_token_id,\n",
        ")\n",
        "\n",
        "# ---- chat frame + prompt slicing + cleanup ----\n",
        "SYS = (\"Follow instructions exactly. Never repeat the prompt. \"\n",
        "       \"Never invent facts. If uncertain, output 'UNKNOWN'.\")\n",
        "FEWSHOT = \"Only output: TIME=9:00; PRIME=2.\\nTIME=9:00; PRIME=2\\n\"\n",
        "\n",
        "def chatify(user_text: str) -> str:\n",
        "    msgs = [\n",
        "        {\"role\": \"system\", \"content\": SYS},\n",
        "        {\"role\": \"user\", \"content\": \"Only output: TIME=9:00; PRIME=2.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"TIME=9:00; PRIME=2\"},\n",
        "        {\"role\": \"user\", \"content\": user_text},\n",
        "    ]\n",
        "    return tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "ANGLE = re.compile(r\"<[^>]{0,200}>\")\n",
        "\n",
        "def clean_out(s: str) -> str:\n",
        "    return ANGLE.sub(\"\", (s or \"\")).strip()\n",
        "\n",
        "def decode_new_only(inputs, out_ids) -> str:\n",
        "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
        "    gen_only = out_ids[0][prompt_len:]\n",
        "    return tok.decode(gen_only, skip_special_tokens=True).strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use your installed package; if not installed, stub the memory so A/B still runs.\n",
        "try:\n",
        "    from p_adic_memory import DualSubstrate\n",
        "    MEM = DualSubstrate(dim=128, cycle_minutes=15)\n",
        "except Exception:\n",
        "    MEM = None\n",
        "\n",
        "POLICY = (\"<memory-policy hidden='true'>Use memory facts if present. \"\n",
        "          \"Never print memory tags. If conflict with the prompt, prefer memory.</memory-policy>\")\n",
        "\n",
        "def build_mem_blob(prompt: str) -> str:\n",
        "    if MEM is None:\n",
        "        return \"<mem exact=0 p=0.000>\"\n",
        "    toks = prompt.split()\n",
        "    for i, t in enumerate(toks):\n",
        "        MEM.observe(t, {\"pos\": i % 11, \"role\": \"ctx\"})\n",
        "    recent = toks[-64:]\n",
        "    rec = []\n",
        "    for t in recent:\n",
        "        q = MEM.query(t)  # expects {'exact': bool, 'p': float, ...}\n",
        "        rec.append(f\"<mem exact={int(q.get('exact', False))} p={q.get('p',0.0):.3f}>\")\n",
        "    return \" \".join(rec[:64])\n",
        "\n",
        "def hf_generate(user_text: str) -> str:\n",
        "    chat_str = chatify(user_text)\n",
        "    inputs = tok(chat_str, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.inference_mode():\n",
        "        out = model.generate(**inputs, **GEN_KW)\n",
        "    return clean_out(decode_new_only(inputs, out))\n",
        "\n",
        "def hf_generate_dual(user_text: str) -> str:\n",
        "    mem_blob = build_mem_blob(user_text)\n",
        "    aug_user = f\"{POLICY}\\n<memory hidden='true'>{mem_blob}</memory>\\n\\n{user_text}\"\n",
        "    chat_str = chatify(aug_user)\n",
        "    inputs = tok(chat_str, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.inference_mode():\n",
        "        out = model.generate(**inputs, **GEN_KW)\n",
        "    return clean_out(decode_new_only(inputs, out))\n"
      ],
      "metadata": {
        "id": "KTKIsOS4XVA9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, random, re, time  # ← add time\n",
        "\n",
        "FMT = re.compile(r\"^TIME=\\d{1,2}:\\d{2}; PRIME=\\d+$\")\n",
        "\n",
        "def make_kv_doc(num_noise_pairs=4000, seed=42):\n",
        "    random.seed(seed)\n",
        "    gt_time, gt_prime = \"9:00\", 2\n",
        "    noise = \" \".join(f\"Z{i}:{(i*7)%97};\" for i in range(num_noise_pairs))\n",
        "    payload = f\"{noise} TIME:{gt_time}; PRIME:{gt_prime}; {noise}\"\n",
        "    instr = \"Only output in this exact format: TIME=<time>; PRIME=<n>.\"\n",
        "    return f\"{payload}\\n\\n{instr}\"\n",
        "\n",
        "def run_ruler(gen_fn, noise_sizes=(1000, 4000, 8000, 16000)):\n",
        "    rows = []\n",
        "    for L in noise_sizes:\n",
        "        prompt = make_kv_doc(L)\n",
        "        t0 = time.time()\n",
        "        try:\n",
        "            resp = gen_fn(prompt)\n",
        "        except Exception as e:\n",
        "            resp = f\"ERROR: {type(e).__name__}: {e}\"\n",
        "        lat = round(time.time() - t0, 3)\n",
        "        ok = isinstance(resp, str) and FMT.fullmatch(resp or \"\") and (\"TIME=9:00\" in resp) and (\"PRIME=2\" in resp)\n",
        "        rows.append({\"noise_pairs\": L, \"response\": resp, \"ok\": bool(ok), \"latency_s\": lat})\n",
        "    return rows\n",
        "\n",
        "ruler_baseline = run_ruler(hf_generate)\n",
        "ruler_dual     = run_ruler(hf_generate_dual)\n",
        "\n",
        "with open(\"/content/ruler_baseline.json\",\"w\") as f: json.dump(ruler_baseline, f, indent=2)\n",
        "with open(\"/content/ruler_dual_substrate.json\",\"w\") as f: json.dump(ruler_dual, f, indent=2)\n",
        "\n",
        "print(\"Saved:\", \"/content/ruler_baseline.json\", \"/content/ruler_dual_substrate.json\")\n",
        "\n",
        "def summary(rows):\n",
        "    return [{\"noise_pairs\": r[\"noise_pairs\"], \"acc\": int(r[\"ok\"]), \"latency_s\": r[\"latency_s\"]} for r in rows]\n",
        "\n",
        "print(\"Baseline:\", summary(ruler_baseline))\n",
        "print(\"Dual    :\", summary(ruler_dual))\n"
      ],
      "metadata": {
        "id": "GVTJxCLtaCMf",
        "outputId": "9897d08d-d271-46e8-c67b-33d7c6ed658d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (15702 > 2048). Running this sequence through the model will result in indexing errors\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/ruler_baseline.json /content/ruler_dual_substrate.json\n",
            "Baseline: [{'noise_pairs': 1000, 'acc': 0, 'latency_s': 0.61}, {'noise_pairs': 4000, 'acc': 0, 'latency_s': 0.132}, {'noise_pairs': 8000, 'acc': 0, 'latency_s': 0.257}, {'noise_pairs': 16000, 'acc': 0, 'latency_s': 0.394}]\n",
            "Dual    : [{'noise_pairs': 1000, 'acc': 0, 'latency_s': 0.03}, {'noise_pairs': 4000, 'acc': 0, 'latency_s': 0.069}, {'noise_pairs': 8000, 'acc': 0, 'latency_s': 0.137}, {'noise_pairs': 16000, 'acc': 0, 'latency_s': 0.324}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_5kV9R9n0Jj",
        "outputId": "6f9348f0-8cba-45cd-d3a6-b85329960a15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/p-adic-memory\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building editable for p-adic-memory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# --- clone official repos (source only; no requirements.txt installs) ---\n",
        "!rm -rf /content/LongBench /content/RULER\n",
        "!git clone -q https://github.com/THUDM/LongBench.git /content/LongBench\n",
        "!git clone -q https://github.com/NVIDIA/RULER.git /content/RULER\n",
        "\n",
        "import sys\n",
        "if \"/content/LongBench\" not in sys.path:\n",
        "    sys.path.append(\"/content/LongBench\")\n",
        "if \"/content/RULER\" not in sys.path:\n",
        "    sys.path.append(\"/content/RULER\")\n",
        "\n",
        "# --- your package from GitHub (editable for quick iteration) ---\n",
        "!rm -rf /content/p-adic-memory\n",
        "!git clone -q https://github.com/Berigny/p-adic-memory.git /content/p-adic-memory\n",
        "\n",
        "%cd /content/p-adic-memory\n",
        "!pip install -q -e .\n",
        "\n",
        "src_path = \"/content/p-adic-memory/src\"\n",
        "if src_path not in sys.path:\n",
        "    sys.path.append(src_path)\n",
        "\n",
        "%cd /content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5dxC0CO6InPG",
        "outputId": "1ac0d896-3515-4eb8-c549-5b75315f8fc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LongBench pred.py: True\n",
            "RULER top-level: ['docker', 'scripts', '.gitignore', '.gitattributes', 'README.md', '.git', 'LICENSE']\n",
            "p_adic_memory importable? True\n"
          ]
        }
      ],
      "source": [
        "# --- quick sanity checks ---\n",
        "import os, importlib.util\n",
        "print(\"LongBench pred.py:\", os.path.exists(\"/content/LongBench/pred.py\"))\n",
        "print(\"RULER top-level:\", os.listdir(\"/content/RULER\")[:10])\n",
        "print(\"p_adic_memory importable?\", importlib.util.find_spec(\"p_adic_memory\") is not None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "k76d5ZCSQF2M",
        "outputId": "b9ead2fd-31e1-4f7a-8019-1e0bfe18d7d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Has LongBench inner dir? True\n",
            "Contents: ['eval.py', 'llama_flash_attn_monkey_patch.py', 'metrics.py', 'pred.py']\n"
          ]
        }
      ],
      "source": [
        "# LongBench is script-first; confirm entry scripts exist and explain why Evaluator imports fail\n",
        "import os\n",
        "LB_INNER = '/content/LongBench/LongBench'\n",
        "print('Has LongBench inner dir?', os.path.isdir(LB_INNER))\n",
        "if os.path.isdir(LB_INNER):\n",
        "    print('Contents:', sorted(f for f in os.listdir(LB_INNER) if f.endswith('.py'))[:6])\n",
        "    if not os.path.exists(os.path.join(LB_INNER, 'eval.py')):\n",
        "        print('Note: no eval.py script found — use the custom harness below.')\n",
        "else:\n",
        "    print('Clone LongBench with: !git clone https://github.com/THUDM/LongBench.git /content/LongBench')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chn_3W6Tn0Jj"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Colab T4 runtimes lack wheels for vLLM/flash-attn pinned by LongBench; install only on A100+\n",
        "# !pip install -q vllm vllm-flash-attn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGx2LqcPn0Jj",
        "outputId": "71b0fe62-e570-4d26-c124-df428b029742",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your Hugging Face token (press enter to skip): ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ],
      "source": [
        "# Authenticate with Hugging Face if you intend to use gated checkpoints\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "token = getpass(\"Paste your Hugging Face token (press enter to skip): \")\n",
        "if token:\n",
        "    os.environ[\"HF_TOKEN\"] = token\n",
        "    from huggingface_hub import login\n",
        "    login(token=token)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa5xYOoan0Jk"
      },
      "source": [
        "## 2. Minimal smoke test with the shared harness\n",
        "\n",
        "The following cell uses the shared harness to load the model and run text generation. It loads prompts from `tests/test_cases.json` to ensure consistency."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"torch\", torch.__version__)\n",
        "print(\"transformers\", transformers.__version__)\n",
        "print(\"tokenizers\", tokenizers.__version__)\n",
        "print(\"numpy\", np.__version__)\n"
      ],
      "metadata": {
        "id": "cpZzsbcR_DTu",
        "outputId": "1bc92a6f-8bc8-46bb-d231-40a1a0f30cc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch 2.3.1+cu121\n",
            "transformers 4.44.2\n",
            "tokenizers 0.19.1\n",
            "numpy 2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, json, time\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from p_adic_memory import DualSubstrateMemory  # from your pip package\n",
        "\n",
        "# --- Choose a test model that fits on T4 ---\n",
        "# Good starter: TinyLlama (fast, no token needed)\n",
        "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "# If moving up later (needs token + 4-bit):\n",
        "# MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True, token=os.environ.get(\"HF_TOKEN\"))\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "\n",
        "# --- Dual-substrate memory (tune dim / cycles as you wish) ---\n",
        "mem = DualSubstrateMemory(dim=128, cycle_minutes=15)\n",
        "\n",
        "def stream_tokens(text: str):\n",
        "    # toy stream: (token, label) -> you’ll swap for your true labelling later\n",
        "    # label could be position, role, doc id, etc.\n",
        "    for i, t in enumerate(text.split()):\n",
        "        yield t, {\"pos\": i % 7, \"role\": \"ctx\"}  # simple label\n",
        "\n",
        "def augment_with_memory(prompt: str, tokens_now: list[str]):\n",
        "    # query memory for each current token; attach exact/prob signals as tags\n",
        "    recalls = []\n",
        "    for t in tokens_now:\n",
        "        q = mem.query(t)  # your API returns a structure (e.g., {\"exact\": bool, \"p\": float, ...})\n",
        "        recalls.append(f\"<mem exact={int(q.get('exact', False))} p={q.get('p',0):.3f}>\")\n",
        "    tag = \" \".join(recalls[:64])  # cap the injected tag length\n",
        "    return f\"{prompt}\\n\\n<memory>{tag}</memory>\"\n",
        "\n",
        "def dual_substrate_generate(prompt: str, max_new_tokens=256, temperature=0.2):\n",
        "    # 1) Observe past tokens into memory\n",
        "    for token, label in stream_tokens(prompt):\n",
        "        mem.observe(token, label)\n",
        "    # 2) Build memory-augmented prompt\n",
        "    current_tokens = prompt.split()[-64:]  # sliding window summary of recent tokens\n",
        "    aug = augment_with_memory(prompt, current_tokens)\n",
        "    # 3) Generate\n",
        "    inputs = tok(aug, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.inference_mode():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            pad_token_id=tok.eos_token_id\n",
        "        )\n",
        "    return tok.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# --- quick A/B sanity run ---\n",
        "queries = [\n",
        "    \"Summarise the following log: Alice met Bob at 9:00. They discussed primes 2, 3, 5, 7 and Möbius transforms.\",\n",
        "    \"Recall the meeting time and the smallest prime they discussed.\",\n",
        "]\n",
        "\n",
        "results = []\n",
        "for q in queries:\n",
        "    t0 = time.time()\n",
        "    out = dual_substrate_generate(q, max_new_tokens=64)\n",
        "    dt = time.time() - t0\n",
        "    results.append({\"prompt\": q, \"response\": out, \"latency_s\": round(dt, 3)})\n",
        "\n",
        "# Save for diffing against baseline later\n",
        "with open(\"/content/dual_substrate_smoke.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(\"Saved:\", \"/content/dual_substrate_smoke.json\")\n"
      ],
      "metadata": {
        "id": "2yA3wo07-ztU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQerV2j9n0Jk"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "try:\n",
        "    from p_adic_memory import DualSubstrate\n",
        "    MEM = DualSubstrate(dim=128, cycle_minutes=15)\n",
        "except Exception as e:\n",
        "    print(\"DualSubstrate not available, using stub:\", e)\n",
        "    MEM = None\n",
        "\n",
        "POLICY = (\"<memory-policy hidden='true'>Use memory facts if present. \"\n",
        "          \"Never print memory tags. If conflict with the prompt, prefer memory.</memory-policy>\")\n",
        "\n",
        "def build_mem_blob(prompt: str) -> str:\n",
        "    if MEM is None:\n",
        "        return \"<mem exact=0 p=0.000>\"\n",
        "    toks = prompt.split()\n",
        "    for i, t in enumerate(toks):\n",
        "        MEM.observe(t, {\"pos\": i % 11, \"role\": \"ctx\"})\n",
        "    recent = toks[-64:]\n",
        "    recs = []\n",
        "    for t in recent:\n",
        "        q = MEM.query(t)  # {'exact': bool, 'p': float, ...}\n",
        "        recs.append(f\"<mem exact={int(q.get('exact', False))} p={q.get('p',0.0):.3f}>\")\n",
        "    return \" \".join(recs[:64])\n",
        "\n",
        "def hf_generate_dual(user_text: str) -> str:\n",
        "    mem_blob = build_mem_blob(user_text)\n",
        "    aug_user = f\"{POLICY}\\n<memory hidden='true'>{mem_blob}</memory>\\n\\n{user_text}\"\n",
        "    s = chatify(aug_user)\n",
        "    inputs = tok(s, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.inference_mode():\n",
        "        out = model.generate(**inputs, **GEN_KW)\n",
        "    return clean_out(decode_new_only(inputs, out))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSWa2YiBn0Jl"
      },
      "source": [
        "## tests\n",
        "\n",
        "LongBench and RULER\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQQMe_y8n0Jm"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import json, random, re, time  # ← add time\n",
        "\n",
        "FMT = re.compile(r\"^TIME=\\d{1,2}:\\d{2}; PRIME=\\d+$\")\n",
        "\n",
        "def make_kv_doc(num_noise_pairs=4000, seed=42):\n",
        "    random.seed(seed)\n",
        "    gt_time, gt_prime = \"9:00\", 2\n",
        "    noise = \" \".join(f\"Z{i}:{(i*7)%97};\" for i in range(num_noise_pairs))\n",
        "    payload = f\"{noise} TIME:{gt_time}; PRIME:{gt_prime}; {noise}\"\n",
        "    instr = \"Only output in this exact format: TIME=<time>; PRIME=<n>.\"\n",
        "    return f\"{payload}\\n\\n{instr}\"\n",
        "\n",
        "def run_ruler(gen_fn, noise_sizes=(1000, 4000, 8000, 16000)):\n",
        "    rows = []\n",
        "    for L in noise_sizes:\n",
        "        prompt = make_kv_doc(L)\n",
        "        t0 = time.time()\n",
        "        try:\n",
        "            resp = gen_fn(prompt)\n",
        "        except Exception as e:\n",
        "            resp = f\"ERROR: {type(e).__name__}: {e}\"\n",
        "        lat = round(time.time() - t0, 3)\n",
        "        ok = isinstance(resp, str) and FMT.fullmatch(resp or \"\") and (\"TIME=9:00\" in resp) and (\"PRIME=2\" in resp)\n",
        "        rows.append({\"noise_pairs\": L, \"response\": resp, \"ok\": bool(ok), \"latency_s\": lat})\n",
        "    return rows\n",
        "\n",
        "ruler_baseline = run_ruler(hf_generate)\n",
        "ruler_dual     = run_ruler(hf_generate_dual)\n",
        "\n",
        "with open(\"/content/ruler_baseline.json\",\"w\") as f: json.dump(ruler_baseline, f, indent=2)\n",
        "with open(\"/content/ruler_dual_substrate.json\",\"w\") as f: json.dump(ruler_dual, f, indent=2)\n",
        "\n",
        "print(\"Saved:\", \"/content/ruler_baseline.json\", \"/content/ruler_dual_substrate.json\")\n",
        "\n",
        "def summary(rows):\n",
        "    return [{\"noise_pairs\": r[\"noise_pairs\"], \"acc\": int(r[\"ok\"]), \"latency_s\": r[\"latency_s\"]} for r in rows]\n",
        "\n",
        "print(\"Baseline:\", summary(ruler_baseline))\n",
        "print(\"Dual    :\", summary(ruler_dual))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmpEknogn0Jm"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "queries = [\n",
        "  {\"id\": \"summary_1\",\n",
        "   \"prompt\": \"In one sentence, summarise the following log:\\nAlice met Bob at 9:00. They discussed primes 2, 3, 5, 7 and Möbius transforms.\"},\n",
        "  {\"id\": \"recall_1\",\n",
        "   \"prompt\": \"Recall the meeting time and the smallest prime they discussed. Only output in this exact format: TIME=<time>; PRIME=<n>.\"}\n",
        "]\n",
        "\n",
        "def tag_ok(resp, qid):\n",
        "    if \"recall\" in qid:\n",
        "        return bool(FMT.match(resp or \"\"))\n",
        "    return None\n",
        "\n",
        "lb_baseline, lb_dual = [], []\n",
        "for q in queries:\n",
        "    t0 = time.time(); r = hf_generate(q[\"prompt\"])\n",
        "    lb_baseline.append({\"id\": q[\"id\"], \"response\": r, \"ok\": tag_ok(r, q[\"id\"]), \"latency_s\": round(time.time()-t0, 3)})\n",
        "\n",
        "for q in queries:\n",
        "    t0 = time.time(); r = hf_generate_dual(q[\"prompt\"])\n",
        "    lb_dual.append({\"id\": q[\"id\"], \"response\": r, \"ok\": tag_ok(r, q[\"id\"]), \"latency_s\": round(time.time()-t0, 3)})\n",
        "\n",
        "with open(\"/content/longbench_baseline.json\",\"w\") as f: json.dump(lb_baseline, f, indent=2)\n",
        "with open(\"/content/longbench_dual_substrate.json\",\"w\") as f: json.dump(lb_dual, f, indent=2)\n",
        "\n",
        "print(\"Saved:\", \"/content/longbench_baseline.json\", \"/content/longbench_dual_substrate.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dDQXaLPHnj7"
      },
      "outputs": [],
      "source": [
        "# Prompt slicing sanity check\n",
        "GEN_KW_DEBUG = dict(baseline_defaults)\n",
        "GEN_KW_DEBUG['max_new_tokens'] = 8\n",
        "\n",
        "text = chatify(baseline_tok, \"Only output: TIME=9:00; PRIME=2.\")\n",
        "ids = baseline_tok(text, return_tensors=\"pt\").to(baseline_model.device)\n",
        "with torch.inference_mode():\n",
        "    out = baseline_model.generate(**ids, **GEN_KW_DEBUG)\n",
        "\n",
        "full = baseline_tok.decode(out[0], skip_special_tokens=True)\n",
        "new = decode_new_only(baseline_tok, ids, out)\n",
        "\n",
        "print(\"FULL====\\n\", full[:300])\n",
        "print(\"\\nNEW====\\n\", new)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2KdWBPrn0Jm"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "for name in [\"longbench_dual_substrate.json\", \"longbench_baseline.json\"]:\n",
        "    path = Path(\"/content\") / name\n",
        "    if not path.exists():\n",
        "        print(f\"Missing {name}; run the harness cell above first.\")\n",
        "        continue\n",
        "    with path.open() as f:\n",
        "        data = json.load(f)\n",
        "    print(f\"\\n{name} (records={len(data)}):\")\n",
        "    for item in data:\n",
        "        snippet = item[\"prompt\"][:48].replace(\"\\n\", \" \")\n",
        "        print(\"- prompt[:48]={!r} | latency={}\".format(snippet, item.get(\"latency_s\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddxESaHPn0Jm"
      },
      "source": [
        "## 4. RULER evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXFDO-B-n0Jn"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat > /content/ruler_adapter.py <<'PY'\n",
        "import os\n",
        "import sys\n",
        "\n",
        "if \"/content\" not in sys.path:\n",
        "    sys.path.append(\"/content\")\n",
        "\n",
        "from dual_substrate_adapter import DualSubstrateGenerator\n",
        "\n",
        "_model = None\n",
        "\n",
        "\n",
        "def load_model():\n",
        "    global _model\n",
        "    if _model is None:\n",
        "        name = os.environ.get(\"RULER_MODEL\", \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
        "        _model = DualSubstrateGenerator(name, hf_token=os.environ.get(\"HF_TOKEN\"))\n",
        "    return _model\n",
        "\n",
        "\n",
        "def generate(prompt: str) -> str:\n",
        "    model = load_model()\n",
        "    return model.generate(prompt, max_new_tokens=256)\n",
        "PY\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56t_anUYn0Jn"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, subprocess, sys\n",
        "\n",
        "os.environ[\"PYTHONPATH\"] = f\"/content:{os.environ.get('PYTHONPATH', '')}\"\n",
        "os.environ[\"RULER_MODEL\"] = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "cmd = [\n",
        "    sys.executable,\n",
        "    '-m',\n",
        "    'ruler.evaluate',\n",
        "    '--model',\n",
        "    'custom',\n",
        "    '--custom_module',\n",
        "    'ruler_adapter',\n",
        "    '--tasks',\n",
        "    'kv_retrieval',\n",
        "    '--context_lengths',\n",
        "    '4k,8k',\n",
        "    '--num_samples',\n",
        "    '50',\n",
        "]\n",
        "\n",
        "print('Running:', ' '.join(cmd))\n",
        "completed = subprocess.run(cmd, capture_output=True, text=True)\n",
        "print(completed.stdout)\n",
        "print(completed.stderr)\n",
        "\n",
        "with open('/content/ruler_dual_substrate.txt', 'w') as f:\n",
        "    f.write(completed.stdout)\n",
        "\n",
        "print('Saved:', '/content/ruler_dual_substrate.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK0uV5yYn0Jn"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Optional vanilla RULER baseline using transformers only\n",
        "%%bash\n",
        "cat > /content/ruler_vanilla_adapter.py <<'PY'\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "if \"/content\" not in sys.path:\n",
        "    sys.path.append(\"/content\")\n",
        "\n",
        "from dual_substrate_adapter import (\n",
        "    ALLOWED_GEN_KW,\n",
        "    GEN_KW_BASE,\n",
        "    chatify,\n",
        "    clean_output,\n",
        "    decode_new_only,\n",
        "    enforce_recall_format,\n",
        ")\n",
        "\n",
        "_model = None\n",
        "_tok = None\n",
        "_defaults = None\n",
        "\n",
        "\n",
        "def load_model():\n",
        "    global _model, _tok, _defaults\n",
        "    if _model is None or _tok is None or _defaults is None:\n",
        "        name = os.environ.get(\"RULER_MODEL\", \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
        "        qconf = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "        )\n",
        "        _tok = AutoTokenizer.from_pretrained(name, token=os.environ.get(\"HF_TOKEN\"))\n",
        "        _model = AutoModelForCausalLM.from_pretrained(\n",
        "            name,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True,\n",
        "            quantization_config=qconf,\n",
        "        )\n",
        "        _defaults = dict(GEN_KW_BASE)\n",
        "        _defaults[\"pad_token_id\"] = _tok.eos_token_id\n",
        "        _defaults[\"eos_token_id\"] = _tok.eos_token_id\n",
        "    return _tok, _model, _defaults\n",
        "\n",
        "\n",
        "def build_generation_kwargs(base_settings, max_new_tokens, **overrides):\n",
        "    settings = dict(base_settings)\n",
        "    settings[\"max_new_tokens\"] = max_new_tokens\n",
        "    for key, value in overrides.items():\n",
        "        if key in ALLOWED_GEN_KW and value is not None:\n",
        "            settings[key] = value\n",
        "    return settings\n",
        "\n",
        "\n",
        "def generate(prompt: str) -> str:\n",
        "    tok, model, defaults = load_model()\n",
        "    chat_prompt = chatify(tok, prompt)\n",
        "    inputs = tok(chat_prompt, return_tensors=\"pt\").to(model.device)\n",
        "    settings = build_generation_kwargs(defaults, 256)\n",
        "    with torch.inference_mode():\n",
        "        output = model.generate(**inputs, **settings)\n",
        "    text = decode_new_only(tok, inputs, output)\n",
        "    text = clean_output(text)\n",
        "    return enforce_recall_format(prompt, text)\n",
        "PY\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCHxB-Ron0Jn"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import subprocess, sys\n",
        "\n",
        "cmd = [\n",
        "    sys.executable,\n",
        "    '-m',\n",
        "    'ruler.evaluate',\n",
        "    '--model',\n",
        "    'custom',\n",
        "    '--custom_module',\n",
        "    'ruler_vanilla_adapter',\n",
        "    '--tasks',\n",
        "    'kv_retrieval',\n",
        "    '--context_lengths',\n",
        "    '4k,8k',\n",
        "    '--num_samples',\n",
        "    '50',\n",
        "]\n",
        "\n",
        "print('Running:', ' '.join(cmd))\n",
        "completed = subprocess.run(cmd, capture_output=True, text=True)\n",
        "print(completed.stdout)\n",
        "print(completed.stderr)\n",
        "\n",
        "with open('/content/ruler_baseline.txt', 'w') as f:\n",
        "    f.write(completed.stdout)\n",
        "\n",
        "print('Saved:', '/content/ruler_baseline.txt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7-WvjIPn0Jn"
      },
      "source": [
        "## 5. Export and persist results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0Dqr0agn0Jo"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "!ls -lh /content/*longbench*.json /content/*ruler* 2>/dev/null || true\n",
        "!cp /content/longbench_*.json /content/ruler_* /content/drive/MyDrive/ 2>/dev/null || true\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6CrjjJxsGEw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kor6GcPnn0Jo"
      },
      "source": [
        "## 6. Scaling plan\n",
        "\n",
        "1. Swap `MODEL_NAME` to **mistralai/Mistral-7B-Instruct-v0.2** with 4-bit quantisation.\n",
        "2. Increase LongBench `sample_size` (e.g., 25 → 100) and add tasks such as `LongBookSummEng` and additional QA tracks.\n",
        "3. Extend RULER coverage to multi-hop and longer contexts once the pipeline is reliable.\n",
        "4. Introduce vLLM for batching after verifying correctness with Transformers.\n",
        "5. Maintain A/B JSON outputs (`baseline` vs `dual_substrate`) and track latency, VRAM, and accuracy deltas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qxrWXzqn0Jo"
      },
      "source": [
        "## 7. Troubleshooting tips\n",
        "\n",
        "* **CUDA out-of-memory**: lower `max_new_tokens`, revert to the TinyLlama checkpoint, or ensure 4-bit loading is active.\n",
        "* **Tokenizer errors**: set `pad_token_id` to `tok.eos_token_id`.\n",
        "* **Authentication failures**: provide a Hugging Face token and request model access if required.\n",
        "* **Dataset download issues**: run the dataset setup cells once with a stable internet connection.\n",
        "* **Custom module not found**: confirm that `/content` is on `PYTHONPATH` before invoking RULER.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JH4C4fXn0Jo"
      },
      "source": [
        "## 8. Publishing checklist\n",
        "\n",
        "* Commit `dual_substrate_adapter.py`, `ruler_adapter.py`, and this notebook to a dedicated branch (e.g., `colab-benchmark/`).\n",
        "* Archive JSON artefacts (`longbench_*.json`, `ruler_*.txt`) for baseline comparisons.\n",
        "* Summarise the metrics in a short report covering recall, drift, latency, and energy usage.\n"
      ]
    }
  ]
}