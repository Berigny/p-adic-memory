{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPb7l1oC5Qt2Ho0hsoJ+39l",
      "include_colab_link": True
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berigny/p-adic-memory/blob/main/p-adic-memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install p-adic-memory  ← once you publish to PyPI\n",
        "# meanwhile, install straight from GitHub\n",
        "!pip install -q git+https://github.com/Berigny/p-adic-memory.git@main"
      ],
      "metadata": {
        "id": "DTF5UNSJxkcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time, json, random\n",
        "from p_adic_memory import DualSubstrate   # same code as before, just packaged\n",
        "\n",
        "# 25 min @ 160 WPM ≃ 4 000 tokens\n",
        "TOKENS = 4_000\n",
        "ENTITIES = 87                                # match earlier stress test\n",
        "NAMES = [f\"Ent_{i}\" for i in range(ENTITIES)]\n",
        "\n",
        "def generate_trace(n=TOKENS):\n",
        "    \"\"\"synthetic conversation: entity mentioned every ~45 tokens\"\"\"\n",
        "    trace = []\n",
        "    for i in range(n):\n",
        "        if i % 45 == 0:\n",
        "            ent = random.choice(NAMES)\n",
        "            trace.append((ent, 1.0))          # first mention\n",
        "        else:\n",
        "            trace.append((random.choice(NAMES), 0.7))  # remention\n",
        "    return trace\n",
        "\n",
        "brain = DualSubstrate(dim=128, cycle_len=900)\n",
        "trace = generate_trace()\n",
        "\n",
        "t0 = time.time()\n",
        "for token, label in trace:\n",
        "    brain.observe(token, label)\n",
        "elapsed = time.time() - t0\n",
        "\n",
        "stats = brain.stats()\n",
        "stats[\"tokens\"] = TOKENS\n",
        "stats[\"elapsed_s\"] = round(elapsed, 2)\n",
        "stats[\"tok_per_s\"] = round(TOKENS / elapsed, 0)\n",
        "print(json.dumps(stats, indent=2))"
      ],
      "metadata": {
        "id": "zlLUeuV-xpnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# very small proxy for joules: count 128×128 FLOP per token\n",
        "FLOP_PER_TOKEN = 128 * 128\n",
        "total_flop = FLOP_PER_TOKEN * TOKENS\n",
        "print(f\"Total GFLOP: {total_flop/1e9:.2f}\")\n",
        "print(f\"GFLOP/s:     {total_flop/1e9/elapsed:.2f}\")\n",
        "print(f\"Bits in ledger: {stats['ledger_bits']}  ({stats['ledger_bits']/8/1024:.2f} kB)\")"
      ],
      "metadata": {
        "id": "FFYZ2iJvxvKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probes = random.sample(NAMES, 50)\n",
        "correct = 0\n",
        "for ent in probes:\n",
        "    _, mem = brain.query(ent)\n",
        "    if mem: correct += 1\n",
        "print(f\"Recall@50: {correct}/50 = {correct/50:.1%}\")"
      ],
      "metadata": {
        "id": "TzcGKZP3xx7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.init(project=\"p-adic-memory\", name=\"colab-25min\")\n",
        "wandb.log(stats)"
      ],
      "metadata": {
        "id": "oBU8LyiOx06E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2r2tO5ZvKOa",
        "outputId": "e9787ee9-8e32-4dfe-9536-e7a2135a5cf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"symbols\": 1, \"ledger_bits\": 2, \"continuous_dim\": 128, \"step\": 1}\n",
            "{\"symbols\": 3, \"ledger_bits\": 63, \"continuous_dim\": 128, \"step\": 61}\n",
            "{\"symbols\": 3, \"ledger_bits\": 125, \"continuous_dim\": 128, \"step\": 121}\n",
            "{\"symbols\": 3, \"ledger_bits\": 187, \"continuous_dim\": 128, \"step\": 181}\n",
            "{\"symbols\": 3, \"ledger_bits\": 248, \"continuous_dim\": 128, \"step\": 241}\n",
            "Alice   π=0.00  ledger=True\n",
            "Bob     π=0.00  ledger=True\n",
            "Charlie  π=0.00  ledger=False\n",
            "Dave    π=0.00  ledger=False\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Minimal CPU-only reference model of the\n",
        "Berigny continuous–discrete dual substrate\n",
        "ℝ×ℚₚ  (Hilbert-flow + p-adic ledger)\n",
        "\"\"\"\n",
        "\n",
        "import math, random, json\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "# ---------- low-level helpers ----------\n",
        "_SMALL_PRIMES = [i for i in range(2, 10**6) if all(i % d for d in range(2, int(i**0.5)+1))]\n",
        "PRIME_SUPPLY = iter(_SMALL_PRIMES)\n",
        "\n",
        "def next_prime() -> int:\n",
        "    return next(PRIME_SUPPLY)\n",
        "\n",
        "def valuation(n: int, p: int) -> int:\n",
        "    \"\"\"largest k s.t. p^k | n\"\"\"\n",
        "    if n == 0: return 999\n",
        "    k = 0\n",
        "    while n % p == 0: n //= p; k += 1\n",
        "    return k\n",
        "\n",
        "# ---------- continuous substrate ----------\n",
        "class ContinuousCache:\n",
        "    def __init__(self, dim: int = 128):\n",
        "        self.dim = dim\n",
        "        self.x = [0.0] * dim          # current state vector\n",
        "        self.R = []                   # list of projectors (dim×dim lists)\n",
        "\n",
        "    def add_projector(self, R: List[List[float]]):\n",
        "        self.R.append(R)\n",
        "\n",
        "    def expect(self, idx: int) -> float:\n",
        "        \"\"\"π_i(x) = x^T R_i x\"\"\"\n",
        "        Ri = self.R[idx]\n",
        "        return sum(self.x[j] * Ri[j][k] * self.x[k] for j in range(self.dim) for k in range(self.dim))\n",
        "\n",
        "    def gradient_step(self, idx: int, target: float, lr: float = 0.05):\n",
        "        \"\"\"x ← x + η (target - π_i) ∇π_i  (eq. 4 in ms)\"\"\"\n",
        "        Ri = self.R[idx]\n",
        "        pi = self.expect(idx)\n",
        "        err = target - pi\n",
        "        # ∇π_i = 2 R_i x\n",
        "        grad = [0.0]*self.dim\n",
        "        for j in range(self.dim):\n",
        "            grad[j] = 2.0 * sum(Ri[j][k] * self.x[k] for k in range(self.dim))\n",
        "        # update\n",
        "        for j in range(self.dim):\n",
        "            self.x[j] += lr * err * grad[j]\n",
        "\n",
        "    def cycle_automorphism(self, perm: List[int]):\n",
        "        \"\"\"apply orthogonal permutation U_σ to x and reorder R\"\"\"\n",
        "        # Reorder R according to the permutation.\n",
        "        # The permutation should be applied to the indices of R.\n",
        "        self.R = [self.R[perm[i]] for i in range(len(self.R))]\n",
        "\n",
        "# ---------- discrete ledger ----------\n",
        "class PrimeLedger:\n",
        "    def __init__(self):\n",
        "        self.L = 1                      # multiplicative state\n",
        "        self.prime_map: Dict[str, int] = {}  # symbol → prime\n",
        "        self._symbols_list: List[str] = [] # maintain a list of symbols in registration order\n",
        "\n",
        "    def register(self, symbol: str) -> int:\n",
        "        if symbol not in self.prime_map:\n",
        "            self.prime_map[symbol] = next_prime()\n",
        "            self._symbols_list.append(symbol) # Add symbol to the list\n",
        "        return self.prime_map[symbol]\n",
        "\n",
        "    def write(self, symbol: str):\n",
        "        p = self.register(symbol)\n",
        "        self.L *= p\n",
        "\n",
        "    def delete(self, symbol: str):\n",
        "        p = self.prime_map.get(symbol, None)\n",
        "        if p and valuation(self.L, p) > 0:\n",
        "            # divide once (soft delete)\n",
        "            self.L //= p\n",
        "\n",
        "    def check(self, symbol: str) -> bool:\n",
        "        p = self.prime_map.get(symbol, None)\n",
        "        return valuation(self.L, p) > 0 if p else False\n",
        "\n",
        "    def symbols(self) -> List[str]:\n",
        "        return self._symbols_list # Return the ordered list of symbols\n",
        "\n",
        "# ---------- dual substrate engine ----------\n",
        "class DualSubstrate:\n",
        "    def __init__(self, dim: int = 128, cycle_len: int = 60):\n",
        "        self.continuous = ContinuousCache(dim)\n",
        "        self.discrete   = PrimeLedger()\n",
        "        self.cycle_len  = cycle_len\n",
        "        self.step_cnt   = 0\n",
        "        # pre-allocate a random orthogonal permutation for demo\n",
        "        self.perm = list(range(dim))\n",
        "\n",
        "    def _random_projector(self) -> List[List[float]]:\n",
        "        # rank-1 projector  R = v v^T  with ||v||=1\n",
        "        v = [random.gauss(0, 1) for _ in range(self.continuous.dim)]\n",
        "        norm = math.sqrt(sum(x*x for x in v))\n",
        "        v = [x/norm for x in v]\n",
        "        return [[v[i] * v[j] for j in range(self.continuous.dim)] for i in range(self.continuous.dim)]\n",
        "\n",
        "    def observe(self, symbol: str, truth: float):\n",
        "        \"\"\"\n",
        "        symbol: new token/entity\n",
        "        truth : 0/1 label (or soft 0…1) from external world\n",
        "        \"\"\"\n",
        "        # 1. ensure projector exists and get index\n",
        "        if symbol not in self.discrete.prime_map:\n",
        "            self.continuous.add_projector(self._random_projector())\n",
        "            self.discrete.register(symbol) # Register the symbol after adding projector\n",
        "\n",
        "        # Get the index after ensuring the symbol is registered\n",
        "        idx = self.discrete.symbols().index(symbol)\n",
        "\n",
        "\n",
        "        # 2. gradient step on continuous side\n",
        "        self.continuous.gradient_step(idx, truth)\n",
        "\n",
        "        # 3. discrete write if truth ≥ 0.5\n",
        "        if truth >= 0.5:\n",
        "            self.discrete.write(symbol)\n",
        "        else:\n",
        "            self.discrete.delete(symbol)\n",
        "\n",
        "        # 4. cycle maintenance\n",
        "        self.step_cnt += 1\n",
        "        if self.step_cnt % self.cycle_len == 0:\n",
        "            # The permutation should be applied to the indices of R, not the elements of R.\n",
        "            # The permutation list should be of the length of self.continuous.R.\n",
        "            # Since the permutation is used for cycle_automorphism, which reorders R,\n",
        "            # the permutation list needs to match the number of projectors.\n",
        "            # Re-generating permutation based on the current number of projectors.\n",
        "            current_num_projectors = len(self.continuous.R)\n",
        "            self.perm = list(range(current_num_projectors))\n",
        "            random.shuffle(self.perm)\n",
        "\n",
        "            self.continuous.cycle_automorphism(self.perm)\n",
        "\n",
        "    def query(self, symbol: str) -> Tuple[float, bool]:\n",
        "        \"\"\"return (continuous expectation, discrete membership)\"\"\"\n",
        "        if symbol not in self.discrete.prime_map:\n",
        "            return 0.0, False\n",
        "        idx = self.discrete.symbols().index(symbol)\n",
        "        pi = self.continuous.expect(idx)\n",
        "        mem = self.discrete.check(symbol)\n",
        "        return pi, mem\n",
        "\n",
        "    def stats(self):\n",
        "        return {\n",
        "            \"symbols\": len(self.discrete.symbols()),\n",
        "            \"ledger_bits\": self.discrete.L.bit_length(),\n",
        "            \"continuous_dim\": self.continuous.dim,\n",
        "            \"step\": self.step_cnt\n",
        "        }\n",
        "\n",
        "# ---------- demo ----------\n",
        "if __name__ == \"__main__\":\n",
        "    brain = DualSubstrate(dim=128, cycle_len=60)\n",
        "    transcript = [\"Alice\", \"Bob\", \"Alice\", \"Charlie\", \"Bob\", \"Alice\"] * 50   # 300 steps\n",
        "    for t, token in enumerate(transcript):\n",
        "        label = 1.0 if token == \"Alice\" else 0.7 if token == \"Bob\" else 0.3\n",
        "        brain.observe(token, label)\n",
        "        if t % 60 == 0:\n",
        "            print(json.dumps(brain.stats()))\n",
        "\n",
        "    # final query\n",
        "    for name in [\"Alice\", \"Bob\", \"Charlie\", \"Dave\"]:\n",
        "        pi, mem = brain.query(name)\n",
        "        print(f\"{name:6s}  π={pi:.2f}  ledger={mem}\")"
      ]
    }
  ]
}